{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eff0fc81",
   "metadata": {},
   "source": [
    "#### Загружаем данные в all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "9075248b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "7b8cb16f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37518, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>ts</th>\n",
       "      <th>gate_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18</td>\n",
       "      <td>2022-07-29 09:08:54</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>2022-07-29 09:09:54</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18</td>\n",
       "      <td>2022-07-29 09:09:54</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18</td>\n",
       "      <td>2022-07-29 09:10:06</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>2022-07-29 09:10:08</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                   ts  gate_id\n",
       "0       18  2022-07-29 09:08:54        7\n",
       "1       18  2022-07-29 09:09:54        9\n",
       "2       18  2022-07-29 09:09:54        9\n",
       "3       18  2022-07-29 09:10:06        5\n",
       "4       18  2022-07-29 09:10:08        5"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('data/train.csv', index_col=0)\n",
    "print(train.shape)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "f6ccb043",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7125, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ts</th>\n",
       "      <th>gate_id</th>\n",
       "      <th>user_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37518</th>\n",
       "      <td>2023-01-03 08:21:00</td>\n",
       "      <td>9</td>\n",
       "      <td>gini</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37519</th>\n",
       "      <td>2023-01-03 08:21:00</td>\n",
       "      <td>9</td>\n",
       "      <td>gini</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37520</th>\n",
       "      <td>2023-01-03 08:21:18</td>\n",
       "      <td>5</td>\n",
       "      <td>gini</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37521</th>\n",
       "      <td>2023-01-03 08:21:19</td>\n",
       "      <td>5</td>\n",
       "      <td>gini</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37522</th>\n",
       "      <td>2023-01-03 08:21:39</td>\n",
       "      <td>10</td>\n",
       "      <td>gini</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        ts  gate_id user_word\n",
       "37518  2023-01-03 08:21:00        9      gini\n",
       "37519  2023-01-03 08:21:00        9      gini\n",
       "37520  2023-01-03 08:21:18        5      gini\n",
       "37521  2023-01-03 08:21:19        5      gini\n",
       "37522  2023-01-03 08:21:39       10      gini"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('data/test.csv', index_col=0)\n",
    "print(test.shape)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "8e32de22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1595994892816343"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data = pd.concat([train, test], axis=0)\n",
    "all_data['ts'] = pd.to_datetime(all_data['ts'])\n",
    "\n",
    "# Доля тест во всей выборке\n",
    "sum(all_data['user_word'].notnull()) / all_data['user_word'].shape[0] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d58c1541",
   "metadata": {},
   "source": [
    "### Графички"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "5338de01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "plt.figure()\n",
    "plt.xticks(rotation='vertical')\n",
    "all_data['ts'].hist(bins=50)\n",
    "train['ts'].hist(bins=50)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "12fcfa07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_data[\"gate_id\"].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2566aeff",
   "metadata": {},
   "source": [
    "### Генерируем новые фичи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "4d910ac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Only train gates:  0 16\n",
      "Only test gates:  2\n"
     ]
    }
   ],
   "source": [
    "train_gate_list = sorted(list(train['gate_id'].unique()))\n",
    "test_gate_list = sorted(list(test['gate_id'].unique()))\n",
    "\n",
    "only_train = [gate for gate in train_gate_list if gate not in test_gate_list]\n",
    "only_test = [gate for gate in test_gate_list if gate not in train_gate_list]\n",
    "\n",
    "print(\"Only train gates: \", \" \".join(map(str, only_train)))\n",
    "print(\"Only test gates: \", \" \".join(map(str, only_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "97146f5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>ts</th>\n",
       "      <th>gate_id</th>\n",
       "      <th>user_word</th>\n",
       "      <th>gate_-1</th>\n",
       "      <th>gate_0</th>\n",
       "      <th>gate_1</th>\n",
       "      <th>gate_2</th>\n",
       "      <th>gate_3</th>\n",
       "      <th>gate_4</th>\n",
       "      <th>...</th>\n",
       "      <th>gate_7</th>\n",
       "      <th>gate_8</th>\n",
       "      <th>gate_9</th>\n",
       "      <th>gate_10</th>\n",
       "      <th>gate_11</th>\n",
       "      <th>gate_12</th>\n",
       "      <th>gate_13</th>\n",
       "      <th>gate_14</th>\n",
       "      <th>gate_15</th>\n",
       "      <th>gate_16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>2022-07-29 09:08:54</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                  ts  gate_id user_word  gate_-1  gate_0  gate_1  \\\n",
       "0     18.0 2022-07-29 09:08:54        7       NaN    False   False   False   \n",
       "\n",
       "   gate_2  gate_3  gate_4  ...  gate_7  gate_8  gate_9  gate_10  gate_11  \\\n",
       "0   False   False   False  ...    True   False   False    False    False   \n",
       "\n",
       "   gate_12  gate_13  gate_14  gate_15  gate_16  \n",
       "0    False    False    False    False    False  \n",
       "\n",
       "[1 rows x 22 columns]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1st transformation\n",
    "#Adding dummies for gates\n",
    "\n",
    "gates = pd.get_dummies(all_data['gate_id'])\n",
    "gates.columns = [\"gate_\" + str(col) for col in gates.columns]\n",
    "all_data = pd.concat([all_data, gates], axis=1)\n",
    "\n",
    "all_data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "818d1286",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2nd transformation\n",
    "#Adding dummies for days of week\n",
    "\n",
    "\n",
    "days_of_week = [\"Monday\",\"Tuesday\",\"Wednesday\",\"Thursday\",\"Friday\",\"Saturday\",\"Sunday\"]\n",
    "all_data[days_of_week] = pd.get_dummies(all_data['ts'].dt.day_name())[days_of_week]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "2017a0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3rd transformation\n",
    "#Time\n",
    "\n",
    "all_data['hour'] = all_data['ts'].dt.hour\n",
    "all_data['minute'] = all_data['ts'].dt.minute\n",
    "all_data['day'] = all_data['ts'].dt.day\n",
    "all_data['month'] = all_data['ts'].dt.month\n",
    "\n",
    "\n",
    "hours = pd.get_dummies(all_data['ts'].dt.hour)\n",
    "hours.columns = [\"h_\" + str(col) for col in hours.columns]\n",
    "all_data[hours.columns] = hours[hours.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "ef794e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4th transformation\n",
    "# Working and not working days\n",
    "\n",
    "all_data[\"date\"] = all_data[\"ts\"].dt.date\n",
    "count = all_data.groupby(\"date\").size().reset_index(name='count')\n",
    "result = pd.merge(all_data, count, on='date', how='left')\n",
    "\n",
    "result[\"is_weekend\"] = result[\"count\"] < 100\n",
    "result.drop([\"count\", \"date\"], axis=1, inplace=True)\n",
    "\n",
    "all_data = result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "b6208785",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5th transformation\n",
    "# Gate n-grams\n",
    "\n",
    "\n",
    "all_data[\"gate_half\"] = all_data[\"gate_id\"] <= 8\n",
    "\n",
    "for i in range(-1, 12):\n",
    "    all_data[\"triplet_\" + str(i+1)] = (all_data[\"gate_id\"] >= i) & (all_data[\"gate_id\"] <= i+2)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "1d254340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6th transformation\n",
    "# Estimate working, departure and arrival time\n",
    "\n",
    "\n",
    "# Estimate working, departure and arrival time for train and val\n",
    "stats_train = all_data[all_data.notnull()[\"user_id\"] == True] \\\n",
    "    .groupby([\"user_id\", \"month\", \"day\"]).agg([\"min\", \"max\"])[\"ts\"]\n",
    "stats_train[\"diff\"] = stats_train[\"max\"] - stats_train[\"min\"]\n",
    "stats_train.rename({\"diff\": \"diff_train\", \"min\": \"min_train\", \"max\": \"max_train\"}, axis=1, inplace=True)\n",
    "all_data = pd.merge(all_data, stats_train.reset_index(), how=\"left\", on=[\"user_id\", \"month\", \"day\"])\n",
    "\n",
    "\n",
    "# Estimate working, departure and arrival time for test\n",
    "stats_test = all_data[all_data.notnull()[\"user_id\"] == False] \\\n",
    "    .groupby([\"user_word\", \"month\", \"day\"]).agg([\"min\", \"max\"])[\"ts\"]\n",
    "stats_test[\"diff\"] = stats_test[\"max\"] - stats_test[\"min\"]\n",
    "stats_test.rename({\"diff\": \"diff_test\", \"min\": \"min_test\", \"max\": \"max_test\"}, axis=1, inplace=True)\n",
    "all_data = pd.merge(all_data, stats_test.reset_index(), how=\"left\", on=[\"user_word\", \"month\", \"day\"])\n",
    "\n",
    "\n",
    "# Set unified column name\n",
    "all_data[\"diff\"] = all_data[\"diff_train\"].fillna(all_data[\"diff_test\"])\n",
    "all_data[\"min\"] = all_data[\"min_train\"].fillna(all_data[\"min_test\"])\n",
    "all_data[\"max\"] = all_data[\"max_train\"].fillna(all_data[\"max_test\"])\n",
    "\n",
    "# Drop auxiliary columns\n",
    "all_data.drop([\"min_train\", \"max_train\", \"diff_train\"], axis=1, inplace=True)\n",
    "all_data.drop([\"min_test\", \"max_test\", \"diff_test\"], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "c97ef96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7th transformation\n",
    "# Transform times from 6th point\n",
    "all_data[\"diff_hour\"] = all_data[\"diff\"].dt.seconds // 3600\n",
    "all_data[\"diff_min\"] = all_data[\"diff\"].dt.seconds % 3600 // 60\n",
    "\n",
    "all_data[\"arrival_hour\"] = all_data[\"min\"].dt.hour\n",
    "all_data[\"arrival_min\"] = all_data[\"min\"].dt.minute\n",
    "\n",
    "all_data[\"departure_hour\"] = all_data[\"max\"].dt.hour\n",
    "all_data[\"departure_min\"] = all_data[\"max\"].dt.minute\n",
    "\n",
    "all_data.drop([\"diff\", \"min\", \"max\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "c631fe79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>ts</th>\n",
       "      <th>gate_id</th>\n",
       "      <th>user_word</th>\n",
       "      <th>gate_-1</th>\n",
       "      <th>gate_0</th>\n",
       "      <th>gate_1</th>\n",
       "      <th>gate_2</th>\n",
       "      <th>gate_3</th>\n",
       "      <th>gate_4</th>\n",
       "      <th>...</th>\n",
       "      <th>triplet_9</th>\n",
       "      <th>triplet_10</th>\n",
       "      <th>triplet_11</th>\n",
       "      <th>triplet_12</th>\n",
       "      <th>diff_hour</th>\n",
       "      <th>diff_min</th>\n",
       "      <th>arrival_hour</th>\n",
       "      <th>arrival_min</th>\n",
       "      <th>departure_hour</th>\n",
       "      <th>departure_min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>2022-07-29 09:08:54</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>9</td>\n",
       "      <td>33</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18.0</td>\n",
       "      <td>2022-07-29 09:09:54</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>9</td>\n",
       "      <td>33</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.0</td>\n",
       "      <td>2022-07-29 09:09:54</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>9</td>\n",
       "      <td>33</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18.0</td>\n",
       "      <td>2022-07-29 09:10:06</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>9</td>\n",
       "      <td>33</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18.0</td>\n",
       "      <td>2022-07-29 09:10:08</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>9</td>\n",
       "      <td>33</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44638</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-02-24 19:43:36</td>\n",
       "      <td>11</td>\n",
       "      <td>collinear</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "      <td>31</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>19</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44639</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-02-24 19:44:00</td>\n",
       "      <td>4</td>\n",
       "      <td>collinear</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>9</td>\n",
       "      <td>31</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>19</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44640</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-02-24 19:44:01</td>\n",
       "      <td>4</td>\n",
       "      <td>collinear</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>9</td>\n",
       "      <td>31</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>19</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44641</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-02-24 19:44:09</td>\n",
       "      <td>9</td>\n",
       "      <td>collinear</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>9</td>\n",
       "      <td>31</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>19</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44642</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-02-24 19:44:09</td>\n",
       "      <td>9</td>\n",
       "      <td>collinear</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>9</td>\n",
       "      <td>31</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>19</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>44643 rows × 75 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id                  ts  gate_id  user_word  gate_-1  gate_0  \\\n",
       "0         18.0 2022-07-29 09:08:54        7        NaN    False   False   \n",
       "1         18.0 2022-07-29 09:09:54        9        NaN    False   False   \n",
       "2         18.0 2022-07-29 09:09:54        9        NaN    False   False   \n",
       "3         18.0 2022-07-29 09:10:06        5        NaN    False   False   \n",
       "4         18.0 2022-07-29 09:10:08        5        NaN    False   False   \n",
       "...        ...                 ...      ...        ...      ...     ...   \n",
       "44638      NaN 2023-02-24 19:43:36       11  collinear    False   False   \n",
       "44639      NaN 2023-02-24 19:44:00        4  collinear    False   False   \n",
       "44640      NaN 2023-02-24 19:44:01        4  collinear    False   False   \n",
       "44641      NaN 2023-02-24 19:44:09        9  collinear    False   False   \n",
       "44642      NaN 2023-02-24 19:44:09        9  collinear    False   False   \n",
       "\n",
       "       gate_1  gate_2  gate_3  gate_4  ...  triplet_9  triplet_10  triplet_11  \\\n",
       "0       False   False   False   False  ...      False       False       False   \n",
       "1       False   False   False   False  ...       True        True       False   \n",
       "2       False   False   False   False  ...       True        True       False   \n",
       "3       False   False   False   False  ...      False       False       False   \n",
       "4       False   False   False   False  ...      False       False       False   \n",
       "...       ...     ...     ...     ...  ...        ...         ...         ...   \n",
       "44638   False   False   False   False  ...      False        True        True   \n",
       "44639   False   False   False    True  ...      False       False       False   \n",
       "44640   False   False   False    True  ...      False       False       False   \n",
       "44641   False   False   False   False  ...       True        True       False   \n",
       "44642   False   False   False   False  ...       True        True       False   \n",
       "\n",
       "       triplet_12  diff_hour  diff_min  arrival_hour  arrival_min  \\\n",
       "0           False          9        33             9            8   \n",
       "1           False          9        33             9            8   \n",
       "2           False          9        33             9            8   \n",
       "3           False          9        33             9            8   \n",
       "4           False          9        33             9            8   \n",
       "...           ...        ...       ...           ...          ...   \n",
       "44638        True          9        31            10           12   \n",
       "44639       False          9        31            10           12   \n",
       "44640       False          9        31            10           12   \n",
       "44641       False          9        31            10           12   \n",
       "44642       False          9        31            10           12   \n",
       "\n",
       "       departure_hour  departure_min  \n",
       "0                  18             41  \n",
       "1                  18             41  \n",
       "2                  18             41  \n",
       "3                  18             41  \n",
       "4                  18             41  \n",
       "...               ...            ...  \n",
       "44638              19             44  \n",
       "44639              19             44  \n",
       "44640              19             44  \n",
       "44641              19             44  \n",
       "44642              19             44  \n",
       "\n",
       "[44643 rows x 75 columns]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "add83eb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13, 75)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data[(all_data['user_word'] == \"collinear\") & (all_data['month'] == 2) & (all_data['day'] == 24)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "30b07ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8th transformation\n",
    "# Gates number\n",
    "\n",
    "\n",
    "all_data['count_train'] = all_data.groupby(['user_id', 'month', 'day'])['ts'].transform('count')\n",
    "all_data['count_test'] = all_data.groupby(['user_word', 'month', 'day'])['ts'].transform('count')\n",
    "all_data['gates_today'] = all_data['count_train'].fillna(all_data['count_test'])\n",
    "all_data.drop(['count_train', 'count_test'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "forsomereason = all_data.groupby(['user_id'])['gates_today'].agg([\"mean\", \"std\"])\n",
    "forsomereason.rename({\"mean\": \"mean_train\", \"std\": \"std_train\"}, axis=1, inplace=True)\n",
    "all_data = pd.merge(all_data, forsomereason, on=\"user_id\", how=\"left\")\n",
    "\n",
    "forsomereason = all_data.groupby(['user_word'])['gates_today'].agg([\"mean\", \"std\"])\n",
    "forsomereason.rename({\"mean\": \"mean_test\", \"std\": \"std_test\"}, axis=1, inplace=True)\n",
    "all_data = pd.merge(all_data, forsomereason, on=\"user_word\", how=\"left\")\n",
    "all_data[\"gates_avg\"] = all_data[\"mean_train\"].fillna(all_data[\"mean_test\"])\n",
    "all_data[\"gates_std\"] = all_data[\"std_train\"].fillna(all_data[\"std_test\"])\n",
    "all_data.drop(['mean_train', 'mean_test', \"std_test\", \"std_train\"], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "e322bbbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['user_id', 'ts', 'gate_id', 'user_word', 'gate_-1', 'gate_0', 'gate_1',\n",
      "       'gate_2', 'gate_3', 'gate_4', 'gate_5', 'gate_6', 'gate_7', 'gate_8',\n",
      "       'gate_9', 'gate_10', 'gate_11', 'gate_12', 'gate_13', 'gate_14',\n",
      "       'gate_15', 'gate_16', 'Monday', 'Tuesday', 'Wednesday', 'Thursday',\n",
      "       'Friday', 'Saturday', 'Sunday', 'hour', 'minute', 'day', 'month', 'h_0',\n",
      "       'h_1', 'h_3', 'h_6', 'h_7', 'h_8', 'h_9', 'h_10', 'h_11', 'h_12',\n",
      "       'h_13', 'h_14', 'h_15', 'h_16', 'h_17', 'h_18', 'h_19', 'h_20', 'h_21',\n",
      "       'h_22', 'h_23', 'is_weekend', 'gate_half', 'triplet_0', 'triplet_1',\n",
      "       'triplet_2', 'triplet_3', 'triplet_4', 'triplet_5', 'triplet_6',\n",
      "       'triplet_7', 'triplet_8', 'triplet_9', 'triplet_10', 'triplet_11',\n",
      "       'triplet_12', 'diff_hour', 'diff_min', 'arrival_hour', 'arrival_min',\n",
      "       'departure_hour', 'departure_min', 'gates_today', 'gates_avg',\n",
      "       'gates_std'],\n",
      "      dtype='object') 78\n"
     ]
    }
   ],
   "source": [
    "print(all_data.columns, len(all_data.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "298b9b31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "max      2022-12-31 20:39:31\n",
       "count                  37518\n",
       "Name: ts, dtype: object"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['ts'].agg(['max','count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "e7e72539",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "min      2023-01-03 08:21:00\n",
       "max      2023-02-24 19:44:09\n",
       "count                   7125\n",
       "Name: ts, dtype: object"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['ts'].agg(['min','max','count'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460f84ec",
   "metadata": {},
   "source": [
    "### Подготовить трэйн и валидацию\n",
    "\n",
    "В результате получается два датафрейма.\n",
    "- train - записи с начала до 30 ноября\n",
    "- validation - записи с 30 ноября до 31 декабря"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "0dfd2c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подготовим данные для train, test\n",
    "\n",
    "train_idx = all_data['user_word'].isnull()\n",
    "not_test = all_data[train_idx].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "00b881aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_index = not_test['ts'] > '2022-11-30'\n",
    "\n",
    "train = not_test[~val_index].copy()\n",
    "validation = not_test[val_index].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "9811e80e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((30535, 78), (44643, 78), (6983, 78))"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, all_data.shape, validation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "dc1e270c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Подготовим данные для train, validation из train\n",
    "\n",
    "\n",
    "# X = train[~val_index].copy()\n",
    "# X_val = train[val_index].copy()\n",
    "\n",
    "# y = X['user_id'].astype(int)\n",
    "# y_val = X_val['user_id'].astype(int)\n",
    "\n",
    "# #Доля на валидации\n",
    "# sum(val_index) / val_index.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fffb05f",
   "metadata": {},
   "source": [
    "### Варианты с классическим ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "43191a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "abb2d699",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train[\"user_id\"].astype(int)\n",
    "X = train.drop([\"user_id\", \"user_word\", \"ts\"], axis=1)\n",
    "\n",
    "y_val = validation[\"user_id\"].astype(int)\n",
    "X_val = validation.drop([\"user_id\", \"user_word\", \"ts\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af09a941",
   "metadata": {},
   "source": [
    "##### Scaling (отключен)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "c59eba30",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_scale = True\n",
    "\n",
    "\n",
    "if to_scale:\n",
    "    \n",
    "    # Сделаем нормирование \n",
    "    scaler_X = StandardScaler()\n",
    "    scaler_X_val = StandardScaler()\n",
    "    \n",
    "    X = pd.DataFrame(scaler_X.fit_transform(X), columns=X.columns)\n",
    "    X_val = pd.DataFrame(scaler_X_val.fit_transform(X_val), columns=X_val.columns)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d870d954",
   "metadata": {},
   "source": [
    "##### Начинаем обучени\n",
    "Моделька запихивается в переменную model, чтоб потом можно было ее обучить на настоящем train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "7db73859",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = KNeighborsClassifier(n_neighbors=15, metric='cosine') #104 14\n",
    "# model = CatBoostClassifier(learning_rate=0.01, loss_function='MultiClass', num_trees=10000)\n",
    "# model = RandomForestClassifier(n_estimators=1000, max_depth=30, min_samples_split=10)\n",
    "clf = model.fit(X, y)\n",
    "\n",
    "y_pred = clf.predict(X)\n",
    "\n",
    "y_val_pred = clf.predict(X_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2704c44",
   "metadata": {},
   "source": [
    "##### Избавимся от повторов в ответах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 933,
   "id": "0d9ecd15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30535, 50)"
      ]
     },
     "execution_count": 933,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_proba = clf.predict_proba(X)\n",
    "y_pred_proba.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 949,
   "id": "b44e1c4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>true</th>\n",
       "      <th>preds_0</th>\n",
       "      <th>preds_1</th>\n",
       "      <th>preds_2</th>\n",
       "      <th>preds_3</th>\n",
       "      <th>preds_4</th>\n",
       "      <th>preds_5</th>\n",
       "      <th>preds_6</th>\n",
       "      <th>preds_7</th>\n",
       "      <th>preds_8</th>\n",
       "      <th>...</th>\n",
       "      <th>preds_40</th>\n",
       "      <th>preds_41</th>\n",
       "      <th>preds_42</th>\n",
       "      <th>preds_43</th>\n",
       "      <th>preds_44</th>\n",
       "      <th>preds_45</th>\n",
       "      <th>preds_46</th>\n",
       "      <th>preds_47</th>\n",
       "      <th>preds_48</th>\n",
       "      <th>preds_49</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>user_0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.232356</td>\n",
       "      <td>0.048586</td>\n",
       "      <td>0.034974</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.043455</td>\n",
       "      <td>0.002513</td>\n",
       "      <td>0.000524</td>\n",
       "      <td>0.018220</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027539</td>\n",
       "      <td>0.019581</td>\n",
       "      <td>0.021257</td>\n",
       "      <td>0.033403</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.039267</td>\n",
       "      <td>0.012880</td>\n",
       "      <td>0.065236</td>\n",
       "      <td>0.001257</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.055032</td>\n",
       "      <td>0.284047</td>\n",
       "      <td>0.087259</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.035867</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011242</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025589</td>\n",
       "      <td>0.013919</td>\n",
       "      <td>0.014882</td>\n",
       "      <td>0.022270</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027837</td>\n",
       "      <td>0.002570</td>\n",
       "      <td>0.045824</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>0.007923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_11</th>\n",
       "      <td>11.0</td>\n",
       "      <td>0.033141</td>\n",
       "      <td>0.022543</td>\n",
       "      <td>0.014066</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.054046</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025915</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024663</td>\n",
       "      <td>0.022447</td>\n",
       "      <td>0.022929</td>\n",
       "      <td>0.030250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.048362</td>\n",
       "      <td>0.017919</td>\n",
       "      <td>0.055395</td>\n",
       "      <td>0.002890</td>\n",
       "      <td>0.027360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_12</th>\n",
       "      <td>12.0</td>\n",
       "      <td>0.026650</td>\n",
       "      <td>0.005562</td>\n",
       "      <td>0.006785</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033191</td>\n",
       "      <td>0.001589</td>\n",
       "      <td>0.000856</td>\n",
       "      <td>0.057885</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020905</td>\n",
       "      <td>0.008313</td>\n",
       "      <td>0.029279</td>\n",
       "      <td>0.018949</td>\n",
       "      <td>0.000306</td>\n",
       "      <td>0.045355</td>\n",
       "      <td>0.013875</td>\n",
       "      <td>0.027323</td>\n",
       "      <td>0.003851</td>\n",
       "      <td>0.009719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_14</th>\n",
       "      <td>14.0</td>\n",
       "      <td>0.007061</td>\n",
       "      <td>0.003053</td>\n",
       "      <td>0.001908</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009733</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014695</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018130</td>\n",
       "      <td>0.006298</td>\n",
       "      <td>0.012786</td>\n",
       "      <td>0.007824</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004008</td>\n",
       "      <td>0.021183</td>\n",
       "      <td>0.005916</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>0.001908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_15</th>\n",
       "      <td>15.0</td>\n",
       "      <td>0.020328</td>\n",
       "      <td>0.041705</td>\n",
       "      <td>0.035672</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.038033</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>0.027869</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044262</td>\n",
       "      <td>0.011016</td>\n",
       "      <td>0.021246</td>\n",
       "      <td>0.019213</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.038820</td>\n",
       "      <td>0.017246</td>\n",
       "      <td>0.050164</td>\n",
       "      <td>0.000525</td>\n",
       "      <td>0.011803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_17</th>\n",
       "      <td>17.0</td>\n",
       "      <td>0.041108</td>\n",
       "      <td>0.063848</td>\n",
       "      <td>0.036735</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027114</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019242</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012245</td>\n",
       "      <td>0.005248</td>\n",
       "      <td>0.003499</td>\n",
       "      <td>0.014869</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033819</td>\n",
       "      <td>0.010204</td>\n",
       "      <td>0.082507</td>\n",
       "      <td>0.001458</td>\n",
       "      <td>0.017493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_18</th>\n",
       "      <td>18.0</td>\n",
       "      <td>0.018909</td>\n",
       "      <td>0.044797</td>\n",
       "      <td>0.052728</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.059898</td>\n",
       "      <td>0.000381</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007170</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018464</td>\n",
       "      <td>0.008756</td>\n",
       "      <td>0.012183</td>\n",
       "      <td>0.014023</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025317</td>\n",
       "      <td>0.009201</td>\n",
       "      <td>0.035723</td>\n",
       "      <td>0.000317</td>\n",
       "      <td>0.010343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_19</th>\n",
       "      <td>19.0</td>\n",
       "      <td>0.014718</td>\n",
       "      <td>0.008047</td>\n",
       "      <td>0.003714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.063686</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000344</td>\n",
       "      <td>0.028748</td>\n",
       "      <td>...</td>\n",
       "      <td>0.030605</td>\n",
       "      <td>0.018432</td>\n",
       "      <td>0.013549</td>\n",
       "      <td>0.026204</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.057290</td>\n",
       "      <td>0.033494</td>\n",
       "      <td>0.035970</td>\n",
       "      <td>0.000963</td>\n",
       "      <td>0.008597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_20</th>\n",
       "      <td>20.0</td>\n",
       "      <td>0.033913</td>\n",
       "      <td>0.020870</td>\n",
       "      <td>0.018261</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.072174</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033043</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018261</td>\n",
       "      <td>0.047826</td>\n",
       "      <td>0.028696</td>\n",
       "      <td>0.015652</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.079130</td>\n",
       "      <td>0.056522</td>\n",
       "      <td>0.028696</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_22</th>\n",
       "      <td>22.0</td>\n",
       "      <td>0.024096</td>\n",
       "      <td>0.007229</td>\n",
       "      <td>0.016867</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009639</td>\n",
       "      <td>0.060241</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.038554</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033735</td>\n",
       "      <td>0.013253</td>\n",
       "      <td>0.018072</td>\n",
       "      <td>0.034940</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021687</td>\n",
       "      <td>0.033735</td>\n",
       "      <td>0.030120</td>\n",
       "      <td>0.006024</td>\n",
       "      <td>0.013253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_23</th>\n",
       "      <td>23.0</td>\n",
       "      <td>0.031532</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023423</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.045045</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021622</td>\n",
       "      <td>0.022523</td>\n",
       "      <td>0.012613</td>\n",
       "      <td>0.021622</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008108</td>\n",
       "      <td>0.016216</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>0.034234</td>\n",
       "      <td>0.001802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_24</th>\n",
       "      <td>24.0</td>\n",
       "      <td>0.035938</td>\n",
       "      <td>0.002734</td>\n",
       "      <td>0.004297</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001563</td>\n",
       "      <td>0.038672</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020703</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.067969</td>\n",
       "      <td>0.028516</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.014844</td>\n",
       "      <td>0.031641</td>\n",
       "      <td>0.009766</td>\n",
       "      <td>0.013672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_25</th>\n",
       "      <td>25.0</td>\n",
       "      <td>0.013714</td>\n",
       "      <td>0.009714</td>\n",
       "      <td>0.001143</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030857</td>\n",
       "      <td>0.018286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010857</td>\n",
       "      <td>0.014857</td>\n",
       "      <td>0.029714</td>\n",
       "      <td>0.025714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.038286</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.040571</td>\n",
       "      <td>0.019429</td>\n",
       "      <td>0.018857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_26</th>\n",
       "      <td>26.0</td>\n",
       "      <td>0.019433</td>\n",
       "      <td>0.021053</td>\n",
       "      <td>0.044534</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.051822</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002024</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019838</td>\n",
       "      <td>0.021457</td>\n",
       "      <td>0.099190</td>\n",
       "      <td>0.015789</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019433</td>\n",
       "      <td>0.030769</td>\n",
       "      <td>0.054251</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_27</th>\n",
       "      <td>27.0</td>\n",
       "      <td>0.001824</td>\n",
       "      <td>0.000663</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000663</td>\n",
       "      <td>0.003814</td>\n",
       "      <td>0.000663</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004146</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011774</td>\n",
       "      <td>0.003980</td>\n",
       "      <td>0.004312</td>\n",
       "      <td>0.007463</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011609</td>\n",
       "      <td>0.005804</td>\n",
       "      <td>0.003980</td>\n",
       "      <td>0.007297</td>\n",
       "      <td>0.001990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_28</th>\n",
       "      <td>28.0</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.032813</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018750</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014063</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020313</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_29</th>\n",
       "      <td>29.0</td>\n",
       "      <td>0.040676</td>\n",
       "      <td>0.019274</td>\n",
       "      <td>0.012766</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.036045</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012140</td>\n",
       "      <td>...</td>\n",
       "      <td>0.048811</td>\n",
       "      <td>0.033792</td>\n",
       "      <td>0.029662</td>\n",
       "      <td>0.037171</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.032165</td>\n",
       "      <td>0.024155</td>\n",
       "      <td>0.049687</td>\n",
       "      <td>0.001377</td>\n",
       "      <td>0.020526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.053671</td>\n",
       "      <td>0.098354</td>\n",
       "      <td>0.307468</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.039494</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008481</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016709</td>\n",
       "      <td>0.004557</td>\n",
       "      <td>0.013924</td>\n",
       "      <td>0.013291</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.026962</td>\n",
       "      <td>0.004937</td>\n",
       "      <td>0.048861</td>\n",
       "      <td>0.000633</td>\n",
       "      <td>0.016835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_31</th>\n",
       "      <td>31.0</td>\n",
       "      <td>0.023560</td>\n",
       "      <td>0.013089</td>\n",
       "      <td>0.016230</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.039267</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011518</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023560</td>\n",
       "      <td>0.031937</td>\n",
       "      <td>0.043455</td>\n",
       "      <td>0.013613</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021990</td>\n",
       "      <td>0.034555</td>\n",
       "      <td>0.048691</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_32</th>\n",
       "      <td>32.0</td>\n",
       "      <td>0.019226</td>\n",
       "      <td>0.005743</td>\n",
       "      <td>0.006242</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.054057</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012734</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027466</td>\n",
       "      <td>0.047316</td>\n",
       "      <td>0.033708</td>\n",
       "      <td>0.032709</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.051685</td>\n",
       "      <td>0.042322</td>\n",
       "      <td>0.043321</td>\n",
       "      <td>0.003496</td>\n",
       "      <td>0.027466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_33</th>\n",
       "      <td>33.0</td>\n",
       "      <td>0.032097</td>\n",
       "      <td>0.014513</td>\n",
       "      <td>0.006568</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000424</td>\n",
       "      <td>0.055191</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>...</td>\n",
       "      <td>0.040466</td>\n",
       "      <td>0.042585</td>\n",
       "      <td>0.026907</td>\n",
       "      <td>0.031038</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021186</td>\n",
       "      <td>0.019915</td>\n",
       "      <td>0.046822</td>\n",
       "      <td>0.001801</td>\n",
       "      <td>0.014725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_34</th>\n",
       "      <td>34.0</td>\n",
       "      <td>0.027798</td>\n",
       "      <td>0.036462</td>\n",
       "      <td>0.045487</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.040433</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017690</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023466</td>\n",
       "      <td>0.015162</td>\n",
       "      <td>0.019134</td>\n",
       "      <td>0.018051</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041516</td>\n",
       "      <td>0.010108</td>\n",
       "      <td>0.055235</td>\n",
       "      <td>0.009747</td>\n",
       "      <td>0.029603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_35</th>\n",
       "      <td>35.0</td>\n",
       "      <td>0.036397</td>\n",
       "      <td>0.016544</td>\n",
       "      <td>0.005515</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.037132</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023897</td>\n",
       "      <td>...</td>\n",
       "      <td>0.040441</td>\n",
       "      <td>0.012500</td>\n",
       "      <td>0.025735</td>\n",
       "      <td>0.033456</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013235</td>\n",
       "      <td>0.021691</td>\n",
       "      <td>0.055515</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_36</th>\n",
       "      <td>36.0</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.034375</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018750</td>\n",
       "      <td>0.043750</td>\n",
       "      <td>0.028125</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.034375</td>\n",
       "      <td>0.037500</td>\n",
       "      <td>0.018750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_37</th>\n",
       "      <td>37.0</td>\n",
       "      <td>0.016711</td>\n",
       "      <td>0.017571</td>\n",
       "      <td>0.010210</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.073885</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016120</td>\n",
       "      <td>...</td>\n",
       "      <td>0.042128</td>\n",
       "      <td>0.020688</td>\n",
       "      <td>0.021816</td>\n",
       "      <td>0.016335</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041644</td>\n",
       "      <td>0.015852</td>\n",
       "      <td>0.047609</td>\n",
       "      <td>0.000645</td>\n",
       "      <td>0.016228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_38</th>\n",
       "      <td>38.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.084615</td>\n",
       "      <td>...</td>\n",
       "      <td>0.046154</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.046154</td>\n",
       "      <td>0.015385</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.046154</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007692</td>\n",
       "      <td>0.030769</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_39</th>\n",
       "      <td>39.0</td>\n",
       "      <td>0.024654</td>\n",
       "      <td>0.022581</td>\n",
       "      <td>0.016820</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041244</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.013364</td>\n",
       "      <td>...</td>\n",
       "      <td>0.039286</td>\n",
       "      <td>0.025806</td>\n",
       "      <td>0.050576</td>\n",
       "      <td>0.028917</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.022926</td>\n",
       "      <td>0.035599</td>\n",
       "      <td>0.043779</td>\n",
       "      <td>0.001152</td>\n",
       "      <td>0.013479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_40</th>\n",
       "      <td>40.0</td>\n",
       "      <td>0.021488</td>\n",
       "      <td>0.021074</td>\n",
       "      <td>0.010331</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.040083</td>\n",
       "      <td>0.010744</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.053719</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021488</td>\n",
       "      <td>0.015702</td>\n",
       "      <td>0.013223</td>\n",
       "      <td>0.027686</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019008</td>\n",
       "      <td>0.018182</td>\n",
       "      <td>0.018182</td>\n",
       "      <td>0.005372</td>\n",
       "      <td>0.011983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_41</th>\n",
       "      <td>41.0</td>\n",
       "      <td>0.006250</td>\n",
       "      <td>0.012500</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.093750</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028125</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.053125</td>\n",
       "      <td>0.021875</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.056250</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.021875</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_42</th>\n",
       "      <td>42.0</td>\n",
       "      <td>0.022284</td>\n",
       "      <td>0.043454</td>\n",
       "      <td>0.045404</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041783</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010028</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008914</td>\n",
       "      <td>0.001950</td>\n",
       "      <td>0.000836</td>\n",
       "      <td>0.008078</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.037604</td>\n",
       "      <td>0.007799</td>\n",
       "      <td>0.095265</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.069081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_43</th>\n",
       "      <td>43.0</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.216667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_45</th>\n",
       "      <td>45.0</td>\n",
       "      <td>0.007018</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005263</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031579</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010526</td>\n",
       "      <td>0.001754</td>\n",
       "      <td>0.003509</td>\n",
       "      <td>0.014035</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.035088</td>\n",
       "      <td>0.005263</td>\n",
       "      <td>0.008772</td>\n",
       "      <td>0.015789</td>\n",
       "      <td>0.001754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_46</th>\n",
       "      <td>46.0</td>\n",
       "      <td>0.029050</td>\n",
       "      <td>0.005866</td>\n",
       "      <td>0.017318</td>\n",
       "      <td>0.001117</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.042737</td>\n",
       "      <td>0.027933</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015363</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015084</td>\n",
       "      <td>0.018715</td>\n",
       "      <td>0.034916</td>\n",
       "      <td>0.018715</td>\n",
       "      <td>0.001117</td>\n",
       "      <td>0.042458</td>\n",
       "      <td>0.015922</td>\n",
       "      <td>0.014525</td>\n",
       "      <td>0.016760</td>\n",
       "      <td>0.012291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_47</th>\n",
       "      <td>47.0</td>\n",
       "      <td>0.024496</td>\n",
       "      <td>0.022629</td>\n",
       "      <td>0.017849</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.052502</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.032711</td>\n",
       "      <td>...</td>\n",
       "      <td>0.263406</td>\n",
       "      <td>0.030097</td>\n",
       "      <td>0.029350</td>\n",
       "      <td>0.022928</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.039283</td>\n",
       "      <td>0.024421</td>\n",
       "      <td>0.050336</td>\n",
       "      <td>0.000523</td>\n",
       "      <td>0.009186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_48</th>\n",
       "      <td>48.0</td>\n",
       "      <td>0.024426</td>\n",
       "      <td>0.012281</td>\n",
       "      <td>0.004993</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.045074</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015385</td>\n",
       "      <td>...</td>\n",
       "      <td>0.052362</td>\n",
       "      <td>0.230499</td>\n",
       "      <td>0.036167</td>\n",
       "      <td>0.055061</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.051012</td>\n",
       "      <td>0.051012</td>\n",
       "      <td>0.035628</td>\n",
       "      <td>0.001484</td>\n",
       "      <td>0.016194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_49</th>\n",
       "      <td>49.0</td>\n",
       "      <td>0.026908</td>\n",
       "      <td>0.011927</td>\n",
       "      <td>0.010496</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.029676</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014027</td>\n",
       "      <td>...</td>\n",
       "      <td>0.030439</td>\n",
       "      <td>0.028340</td>\n",
       "      <td>0.351336</td>\n",
       "      <td>0.021088</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023282</td>\n",
       "      <td>0.041221</td>\n",
       "      <td>0.026240</td>\n",
       "      <td>0.001718</td>\n",
       "      <td>0.008397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_5</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_50</th>\n",
       "      <td>50.0</td>\n",
       "      <td>0.032583</td>\n",
       "      <td>0.022156</td>\n",
       "      <td>0.012204</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.047749</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.039336</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029502</td>\n",
       "      <td>0.041943</td>\n",
       "      <td>0.020498</td>\n",
       "      <td>0.223697</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.041706</td>\n",
       "      <td>0.042773</td>\n",
       "      <td>0.001185</td>\n",
       "      <td>0.018365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_52</th>\n",
       "      <td>52.0</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.180000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_53</th>\n",
       "      <td>53.0</td>\n",
       "      <td>0.026891</td>\n",
       "      <td>0.016960</td>\n",
       "      <td>0.015814</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.058976</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.026050</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033461</td>\n",
       "      <td>0.024446</td>\n",
       "      <td>0.015508</td>\n",
       "      <td>0.036440</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.239954</td>\n",
       "      <td>0.023835</td>\n",
       "      <td>0.065470</td>\n",
       "      <td>0.002674</td>\n",
       "      <td>0.019862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_54</th>\n",
       "      <td>54.0</td>\n",
       "      <td>0.015655</td>\n",
       "      <td>0.002791</td>\n",
       "      <td>0.006796</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.052063</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027791</td>\n",
       "      <td>...</td>\n",
       "      <td>0.039927</td>\n",
       "      <td>0.047209</td>\n",
       "      <td>0.051335</td>\n",
       "      <td>0.046481</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.044296</td>\n",
       "      <td>0.226942</td>\n",
       "      <td>0.033495</td>\n",
       "      <td>0.003398</td>\n",
       "      <td>0.016019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_55</th>\n",
       "      <td>55.0</td>\n",
       "      <td>0.037787</td>\n",
       "      <td>0.021753</td>\n",
       "      <td>0.019826</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.057365</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000249</td>\n",
       "      <td>0.018397</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028216</td>\n",
       "      <td>0.018583</td>\n",
       "      <td>0.014916</td>\n",
       "      <td>0.027035</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.052704</td>\n",
       "      <td>0.015911</td>\n",
       "      <td>0.273151</td>\n",
       "      <td>0.002237</td>\n",
       "      <td>0.021255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_56</th>\n",
       "      <td>56.0</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005495</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017582</td>\n",
       "      <td>0.008791</td>\n",
       "      <td>0.010989</td>\n",
       "      <td>0.032967</td>\n",
       "      <td>...</td>\n",
       "      <td>0.035165</td>\n",
       "      <td>0.024176</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.009890</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.048352</td>\n",
       "      <td>0.027473</td>\n",
       "      <td>0.034066</td>\n",
       "      <td>0.223077</td>\n",
       "      <td>0.023077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_57</th>\n",
       "      <td>57.0</td>\n",
       "      <td>0.028773</td>\n",
       "      <td>0.010865</td>\n",
       "      <td>0.021127</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.043260</td>\n",
       "      <td>0.001207</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008451</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013883</td>\n",
       "      <td>0.025151</td>\n",
       "      <td>0.013481</td>\n",
       "      <td>0.032797</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.048491</td>\n",
       "      <td>0.017505</td>\n",
       "      <td>0.065392</td>\n",
       "      <td>0.002414</td>\n",
       "      <td>0.217103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_6</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.026663</td>\n",
       "      <td>0.020770</td>\n",
       "      <td>0.018261</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.246091</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015753</td>\n",
       "      <td>...</td>\n",
       "      <td>0.035356</td>\n",
       "      <td>0.021529</td>\n",
       "      <td>0.017095</td>\n",
       "      <td>0.028121</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.044807</td>\n",
       "      <td>0.022579</td>\n",
       "      <td>0.056884</td>\n",
       "      <td>0.001459</td>\n",
       "      <td>0.012894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_7</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.004082</td>\n",
       "      <td>0.002041</td>\n",
       "      <td>0.002041</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.663265</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012245</td>\n",
       "      <td>0.002041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_8</th>\n",
       "      <td>8.0</td>\n",
       "      <td>0.020690</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.175862</td>\n",
       "      <td>0.082759</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006897</td>\n",
       "      <td>0.020690</td>\n",
       "      <td>0.017241</td>\n",
       "      <td>0.079310</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.017241</td>\n",
       "      <td>0.020690</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_9</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.021260</td>\n",
       "      <td>0.013386</td>\n",
       "      <td>0.010461</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.039820</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>0.279865</td>\n",
       "      <td>...</td>\n",
       "      <td>0.049156</td>\n",
       "      <td>0.018110</td>\n",
       "      <td>0.019235</td>\n",
       "      <td>0.049044</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.048594</td>\n",
       "      <td>0.026322</td>\n",
       "      <td>0.035883</td>\n",
       "      <td>0.002137</td>\n",
       "      <td>0.007987</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         true   preds_0   preds_1   preds_2   preds_3   preds_4   preds_5  \\\n",
       "word                                                                        \n",
       "user_0    0.0  0.232356  0.048586  0.034974  0.000000  0.000000  0.043455   \n",
       "user_1    1.0  0.055032  0.284047  0.087259  0.000000  0.000000  0.035867   \n",
       "user_11  11.0  0.033141  0.022543  0.014066  0.000000  0.000000  0.054046   \n",
       "user_12  12.0  0.026650  0.005562  0.006785  0.000000  0.000000  0.033191   \n",
       "user_14  14.0  0.007061  0.003053  0.001908  0.000000  0.000000  0.009733   \n",
       "user_15  15.0  0.020328  0.041705  0.035672  0.000000  0.000000  0.038033   \n",
       "user_17  17.0  0.041108  0.063848  0.036735  0.000000  0.000000  0.027114   \n",
       "user_18  18.0  0.018909  0.044797  0.052728  0.000000  0.000000  0.059898   \n",
       "user_19  19.0  0.014718  0.008047  0.003714  0.000000  0.000000  0.063686   \n",
       "user_20  20.0  0.033913  0.020870  0.018261  0.000000  0.000000  0.072174   \n",
       "user_22  22.0  0.024096  0.007229  0.016867  0.000000  0.009639  0.060241   \n",
       "user_23  23.0  0.031532  0.000000  0.000000  0.000000  0.000000  0.023423   \n",
       "user_24  24.0  0.035938  0.002734  0.004297  0.000000  0.001563  0.038672   \n",
       "user_25  25.0  0.013714  0.009714  0.001143  0.000000  0.000000  0.030857   \n",
       "user_26  26.0  0.019433  0.021053  0.044534  0.000000  0.000000  0.051822   \n",
       "user_27  27.0  0.001824  0.000663  0.000000  0.000000  0.000663  0.003814   \n",
       "user_28  28.0  0.062500  0.003125  0.032813  0.000000  0.000000  0.000000   \n",
       "user_29  29.0  0.040676  0.019274  0.012766  0.000000  0.000000  0.036045   \n",
       "user_3    3.0  0.053671  0.098354  0.307468  0.000000  0.000000  0.039494   \n",
       "user_31  31.0  0.023560  0.013089  0.016230  0.000000  0.000000  0.039267   \n",
       "user_32  32.0  0.019226  0.005743  0.006242  0.000000  0.000000  0.054057   \n",
       "user_33  33.0  0.032097  0.014513  0.006568  0.000000  0.000424  0.055191   \n",
       "user_34  34.0  0.027798  0.036462  0.045487  0.000000  0.000000  0.040433   \n",
       "user_35  35.0  0.036397  0.016544  0.005515  0.000000  0.000000  0.037132   \n",
       "user_36  36.0  0.031250  0.000000  0.000000  0.000000  0.000000  0.015625   \n",
       "user_37  37.0  0.016711  0.017571  0.010210  0.000000  0.000000  0.073885   \n",
       "user_38  38.0  0.000000  0.000000  0.000000  0.000000  0.000000  0.038462   \n",
       "user_39  39.0  0.024654  0.022581  0.016820  0.000000  0.000000  0.041244   \n",
       "user_4    4.0  0.000000  0.000000  0.000000  0.200000  0.000000  0.000000   \n",
       "user_40  40.0  0.021488  0.021074  0.010331  0.000000  0.000000  0.040083   \n",
       "user_41  41.0  0.006250  0.012500  0.003125  0.000000  0.000000  0.093750   \n",
       "user_42  42.0  0.022284  0.043454  0.045404  0.000000  0.000000  0.041783   \n",
       "user_43  43.0  0.016667  0.000000  0.000000  0.000000  0.000000  0.016667   \n",
       "user_45  45.0  0.007018  0.000000  0.000000  0.000000  0.000000  0.005263   \n",
       "user_46  46.0  0.029050  0.005866  0.017318  0.001117  0.000000  0.042737   \n",
       "user_47  47.0  0.024496  0.022629  0.017849  0.000000  0.000000  0.052502   \n",
       "user_48  48.0  0.024426  0.012281  0.004993  0.000000  0.000000  0.045074   \n",
       "user_49  49.0  0.026908  0.011927  0.010496  0.000000  0.000000  0.029676   \n",
       "user_5    5.0  0.000000  0.000000  0.000000  0.000000  0.200000  0.000000   \n",
       "user_50  50.0  0.032583  0.022156  0.012204  0.000000  0.000000  0.047749   \n",
       "user_52  52.0  0.020000  0.000000  0.000000  0.000000  0.000000  0.020000   \n",
       "user_53  53.0  0.026891  0.016960  0.015814  0.000000  0.000000  0.058976   \n",
       "user_54  54.0  0.015655  0.002791  0.006796  0.000000  0.000000  0.052063   \n",
       "user_55  55.0  0.037787  0.021753  0.019826  0.000000  0.000000  0.057365   \n",
       "user_56  56.0  0.014286  0.000000  0.005495  0.000000  0.000000  0.017582   \n",
       "user_57  57.0  0.028773  0.010865  0.021127  0.000000  0.000000  0.043260   \n",
       "user_6    6.0  0.026663  0.020770  0.018261  0.000000  0.000000  0.246091   \n",
       "user_7    7.0  0.004082  0.002041  0.002041  0.000000  0.000000  0.000000   \n",
       "user_8    8.0  0.020690  0.003448  0.000000  0.000000  0.000000  0.003448   \n",
       "user_9    9.0  0.021260  0.013386  0.010461  0.000000  0.000000  0.039820   \n",
       "\n",
       "          preds_6   preds_7   preds_8  ...  preds_40  preds_41  preds_42  \\\n",
       "word                                   ...                                 \n",
       "user_0   0.002513  0.000524  0.018220  ...  0.027539  0.019581  0.021257   \n",
       "user_1   0.000000  0.000000  0.011242  ...  0.025589  0.013919  0.014882   \n",
       "user_11  0.000000  0.000000  0.025915  ...  0.024663  0.022447  0.022929   \n",
       "user_12  0.001589  0.000856  0.057885  ...  0.020905  0.008313  0.029279   \n",
       "user_14  0.000000  0.000000  0.014695  ...  0.018130  0.006298  0.012786   \n",
       "user_15  0.000000  0.000066  0.027869  ...  0.044262  0.011016  0.021246   \n",
       "user_17  0.000000  0.000000  0.019242  ...  0.012245  0.005248  0.003499   \n",
       "user_18  0.000381  0.000000  0.007170  ...  0.018464  0.008756  0.012183   \n",
       "user_19  0.000000  0.000344  0.028748  ...  0.030605  0.018432  0.013549   \n",
       "user_20  0.000000  0.000000  0.033043  ...  0.018261  0.047826  0.028696   \n",
       "user_22  0.000000  0.000000  0.038554  ...  0.033735  0.013253  0.018072   \n",
       "user_23  0.000000  0.000000  0.045045  ...  0.021622  0.022523  0.012613   \n",
       "user_24  0.000000  0.000000  0.046875  ...  0.020703  0.001953  0.067969   \n",
       "user_25  0.018286  0.000000  0.060000  ...  0.010857  0.014857  0.029714   \n",
       "user_26  0.000000  0.000000  0.002024  ...  0.019838  0.021457  0.099190   \n",
       "user_27  0.000663  0.000000  0.004146  ...  0.011774  0.003980  0.004312   \n",
       "user_28  0.018750  0.000000  0.000000  ...  0.014063  0.000000  0.000000   \n",
       "user_29  0.000000  0.000000  0.012140  ...  0.048811  0.033792  0.029662   \n",
       "user_3   0.000000  0.000000  0.008481  ...  0.016709  0.004557  0.013924   \n",
       "user_31  0.000000  0.000000  0.011518  ...  0.023560  0.031937  0.043455   \n",
       "user_32  0.000000  0.000000  0.012734  ...  0.027466  0.047316  0.033708   \n",
       "user_33  0.000000  0.000000  0.012712  ...  0.040466  0.042585  0.026907   \n",
       "user_34  0.000000  0.000000  0.017690  ...  0.023466  0.015162  0.019134   \n",
       "user_35  0.000000  0.000000  0.023897  ...  0.040441  0.012500  0.025735   \n",
       "user_36  0.000000  0.000000  0.034375  ...  0.018750  0.043750  0.028125   \n",
       "user_37  0.000000  0.000000  0.016120  ...  0.042128  0.020688  0.021816   \n",
       "user_38  0.000000  0.000000  0.084615  ...  0.046154  0.000000  0.046154   \n",
       "user_39  0.000000  0.000115  0.013364  ...  0.039286  0.025806  0.050576   \n",
       "user_4   0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.200000   \n",
       "user_40  0.010744  0.000000  0.053719  ...  0.021488  0.015702  0.013223   \n",
       "user_41  0.000000  0.000000  0.028125  ...  0.031250  0.025000  0.053125   \n",
       "user_42  0.000000  0.000000  0.010028  ...  0.008914  0.001950  0.000836   \n",
       "user_43  0.000000  0.000000  0.216667  ...  0.000000  0.000000  0.000000   \n",
       "user_45  0.000000  0.000000  0.031579  ...  0.010526  0.001754  0.003509   \n",
       "user_46  0.027933  0.000000  0.015363  ...  0.015084  0.018715  0.034916   \n",
       "user_47  0.000000  0.000000  0.032711  ...  0.263406  0.030097  0.029350   \n",
       "user_48  0.000000  0.000000  0.015385  ...  0.052362  0.230499  0.036167   \n",
       "user_49  0.000000  0.000000  0.014027  ...  0.030439  0.028340  0.351336   \n",
       "user_5   0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
       "user_50  0.000000  0.000000  0.039336  ...  0.029502  0.041943  0.020498   \n",
       "user_52  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
       "user_53  0.000000  0.000076  0.026050  ...  0.033461  0.024446  0.015508   \n",
       "user_54  0.000000  0.000000  0.027791  ...  0.039927  0.047209  0.051335   \n",
       "user_55  0.000000  0.000249  0.018397  ...  0.028216  0.018583  0.014916   \n",
       "user_56  0.008791  0.010989  0.032967  ...  0.035165  0.024176  0.028571   \n",
       "user_57  0.001207  0.000000  0.008451  ...  0.013883  0.025151  0.013481   \n",
       "user_6   0.000000  0.000000  0.015753  ...  0.035356  0.021529  0.017095   \n",
       "user_7   0.663265  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
       "user_8   0.000000  0.175862  0.082759  ...  0.006897  0.020690  0.017241   \n",
       "user_9   0.000000  0.000112  0.279865  ...  0.049156  0.018110  0.019235   \n",
       "\n",
       "         preds_43  preds_44  preds_45  preds_46  preds_47  preds_48  preds_49  \n",
       "word                                                                           \n",
       "user_0   0.033403  0.000000  0.039267  0.012880  0.065236  0.001257  0.020000  \n",
       "user_1   0.022270  0.000000  0.027837  0.002570  0.045824  0.000107  0.007923  \n",
       "user_11  0.030250  0.000000  0.048362  0.017919  0.055395  0.002890  0.027360  \n",
       "user_12  0.018949  0.000306  0.045355  0.013875  0.027323  0.003851  0.009719  \n",
       "user_14  0.007824  0.000000  0.004008  0.021183  0.005916  0.000191  0.001908  \n",
       "user_15  0.019213  0.000000  0.038820  0.017246  0.050164  0.000525  0.011803  \n",
       "user_17  0.014869  0.000000  0.033819  0.010204  0.082507  0.001458  0.017493  \n",
       "user_18  0.014023  0.000000  0.025317  0.009201  0.035723  0.000317  0.010343  \n",
       "user_19  0.026204  0.000000  0.057290  0.033494  0.035970  0.000963  0.008597  \n",
       "user_20  0.015652  0.000000  0.079130  0.056522  0.028696  0.000000  0.017391  \n",
       "user_22  0.034940  0.000000  0.021687  0.033735  0.030120  0.006024  0.013253  \n",
       "user_23  0.021622  0.000000  0.008108  0.016216  0.027027  0.034234  0.001802  \n",
       "user_24  0.028516  0.000000  0.023438  0.014844  0.031641  0.009766  0.013672  \n",
       "user_25  0.025714  0.000000  0.038286  0.020000  0.040571  0.019429  0.018857  \n",
       "user_26  0.015789  0.000000  0.019433  0.030769  0.054251  0.000000  0.023887  \n",
       "user_27  0.007463  0.000000  0.011609  0.005804  0.003980  0.007297  0.001990  \n",
       "user_28  0.000000  0.000000  0.020313  0.000000  0.000000  0.000000  0.001563  \n",
       "user_29  0.037171  0.000000  0.032165  0.024155  0.049687  0.001377  0.020526  \n",
       "user_3   0.013291  0.000000  0.026962  0.004937  0.048861  0.000633  0.016835  \n",
       "user_31  0.013613  0.000000  0.021990  0.034555  0.048691  0.000000  0.023560  \n",
       "user_32  0.032709  0.000000  0.051685  0.042322  0.043321  0.003496  0.027466  \n",
       "user_33  0.031038  0.000000  0.021186  0.019915  0.046822  0.001801  0.014725  \n",
       "user_34  0.018051  0.000000  0.041516  0.010108  0.055235  0.009747  0.029603  \n",
       "user_35  0.033456  0.000000  0.013235  0.021691  0.055515  0.000000  0.011765  \n",
       "user_36  0.003125  0.000000  0.050000  0.003125  0.034375  0.037500  0.018750  \n",
       "user_37  0.016335  0.000000  0.041644  0.015852  0.047609  0.000645  0.016228  \n",
       "user_38  0.015385  0.000000  0.046154  0.000000  0.007692  0.030769  0.000000  \n",
       "user_39  0.028917  0.000115  0.022926  0.035599  0.043779  0.001152  0.013479  \n",
       "user_4   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "user_40  0.027686  0.000000  0.019008  0.018182  0.018182  0.005372  0.011983  \n",
       "user_41  0.021875  0.000000  0.056250  0.031250  0.021875  0.000000  0.003125  \n",
       "user_42  0.008078  0.000000  0.037604  0.007799  0.095265  0.000000  0.069081  \n",
       "user_43  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "user_45  0.014035  0.000000  0.035088  0.005263  0.008772  0.015789  0.001754  \n",
       "user_46  0.018715  0.001117  0.042458  0.015922  0.014525  0.016760  0.012291  \n",
       "user_47  0.022928  0.000000  0.039283  0.024421  0.050336  0.000523  0.009186  \n",
       "user_48  0.055061  0.000000  0.051012  0.051012  0.035628  0.001484  0.016194  \n",
       "user_49  0.021088  0.000000  0.023282  0.041221  0.026240  0.001718  0.008397  \n",
       "user_5   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "user_50  0.223697  0.000000  0.050000  0.041706  0.042773  0.001185  0.018365  \n",
       "user_52  0.000000  0.180000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "user_53  0.036440  0.000000  0.239954  0.023835  0.065470  0.002674  0.019862  \n",
       "user_54  0.046481  0.000000  0.044296  0.226942  0.033495  0.003398  0.016019  \n",
       "user_55  0.027035  0.000000  0.052704  0.015911  0.273151  0.002237  0.021255  \n",
       "user_56  0.009890  0.000000  0.048352  0.027473  0.034066  0.223077  0.023077  \n",
       "user_57  0.032797  0.000000  0.048491  0.017505  0.065392  0.002414  0.217103  \n",
       "user_6   0.028121  0.000000  0.044807  0.022579  0.056884  0.001459  0.012894  \n",
       "user_7   0.000000  0.000000  0.000000  0.000000  0.000000  0.012245  0.002041  \n",
       "user_8   0.079310  0.000000  0.034483  0.034483  0.017241  0.020690  0.000000  \n",
       "user_9   0.049044  0.000000  0.048594  0.026322  0.035883  0.002137  0.007987  \n",
       "\n",
       "[50 rows x 51 columns]"
      ]
     },
     "execution_count": 949,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "y_word = pd.DataFrame()\n",
    "y_word['word'] = 'user_' + y.astype(str)\n",
    "y_word['true'] = y\n",
    "\n",
    "\n",
    "for i in range(y_pred_proba.shape[1]):\n",
    "    col = y_pred_proba[:,i]\n",
    "    y_word['preds_' + str(i)] = col\n",
    "\n",
    "\n",
    "y_word.groupby([\"word\"]).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 936,
   "id": "8f3247ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true        user_57\n",
       "preds_0      user_0\n",
       "preds_1      user_1\n",
       "preds_2      user_3\n",
       "preds_3      user_4\n",
       "preds_4      user_5\n",
       "preds_5      user_6\n",
       "preds_6      user_7\n",
       "preds_7      user_8\n",
       "preds_8      user_9\n",
       "preds_9     user_11\n",
       "preds_10    user_52\n",
       "preds_11    user_14\n",
       "preds_12    user_15\n",
       "preds_13    user_17\n",
       "preds_14    user_18\n",
       "preds_15    user_19\n",
       "preds_16    user_20\n",
       "preds_17     user_5\n",
       "preds_18    user_23\n",
       "preds_19    user_24\n",
       "preds_20    user_25\n",
       "preds_21    user_26\n",
       "preds_22    user_27\n",
       "preds_23    user_28\n",
       "preds_24    user_29\n",
       "preds_25    user_31\n",
       "preds_26    user_32\n",
       "preds_27    user_33\n",
       "preds_28     user_4\n",
       "preds_29    user_35\n",
       "preds_30    user_36\n",
       "preds_31    user_37\n",
       "preds_32    user_38\n",
       "preds_33    user_39\n",
       "preds_34    user_40\n",
       "preds_35    user_41\n",
       "preds_36    user_42\n",
       "preds_37    user_43\n",
       "preds_38    user_45\n",
       "preds_39    user_46\n",
       "preds_40    user_47\n",
       "preds_41    user_48\n",
       "preds_42    user_49\n",
       "preds_43    user_50\n",
       "preds_44    user_52\n",
       "preds_45    user_53\n",
       "preds_46    user_54\n",
       "preds_47    user_55\n",
       "preds_48    user_56\n",
       "preds_49    user_57\n",
       "dtype: object"
      ]
     },
     "execution_count": 936,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_values = y_word.groupby([\"word\"]).mean().idxmax(axis=0)\n",
    "max_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ada382c",
   "metadata": {},
   "source": [
    "### Нейросетевая попытка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "id": "cebb9798",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.drop([\"ts\", \"user_word\"], axis=1, inplace=True)\n",
    "X_val.drop([\"ts\", \"user_word\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "id": "38dc5686",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 573,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X[\"user_id\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "id": "2ac57c52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0,\n",
       " 1.0,\n",
       " 3.0,\n",
       " 4.0,\n",
       " 5.0,\n",
       " 6.0,\n",
       " 7.0,\n",
       " 8.0,\n",
       " 9.0,\n",
       " 11.0,\n",
       " 12.0,\n",
       " 14.0,\n",
       " 15.0,\n",
       " 17.0,\n",
       " 18.0,\n",
       " 19.0,\n",
       " 20.0,\n",
       " 22.0,\n",
       " 23.0,\n",
       " 24.0,\n",
       " 25.0,\n",
       " 26.0,\n",
       " 27.0,\n",
       " 28.0,\n",
       " 29.0,\n",
       " 31.0,\n",
       " 32.0,\n",
       " 33.0,\n",
       " 34.0,\n",
       " 35.0,\n",
       " 36.0,\n",
       " 37.0,\n",
       " 38.0,\n",
       " 39.0,\n",
       " 40.0,\n",
       " 41.0,\n",
       " 42.0,\n",
       " 43.0,\n",
       " 45.0,\n",
       " 46.0,\n",
       " 47.0,\n",
       " 48.0,\n",
       " 49.0,\n",
       " 50.0,\n",
       " 52.0,\n",
       " 53.0,\n",
       " 54.0,\n",
       " 55.0,\n",
       " 56.0,\n",
       " 57.0]"
      ]
     },
     "execution_count": 577,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(X[\"user_id\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "id": "465ac5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataframe, target_column):\n",
    "        self.dataframe = dataframe\n",
    "        self.target_column = target_column\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Получаем данные и метки\n",
    "        row = self.dataframe.iloc[idx]\n",
    "        features = row.drop(self.target_column).values.astype(float)  # Входные данные\n",
    "        label = row[self.target_column]  # Целевая переменная\n",
    "        \n",
    "        return torch.tensor(features, dtype=torch.float32), torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "\n",
    "# Создаем экземпляр Dataset\n",
    "target_column = 'user_id'\n",
    "dataset = CustomDataset(X, target_column)\n",
    "\n",
    "# Создаем DataLoader\n",
    "data_loader = DataLoader(dataset, batch_size=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f9a8c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "id": "3d78b883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 4.5669\n",
      "Epoch [2/10], Loss: 1.9147\n",
      "Epoch [3/10], Loss: 0.4321\n",
      "Epoch [4/10], Loss: 2.3233\n",
      "Epoch [5/10], Loss: 1.2663\n",
      "Epoch [6/10], Loss: 2.9918\n",
      "Epoch [7/10], Loss: 0.0277\n",
      "Epoch [8/10], Loss: 0.0565\n",
      "Epoch [9/10], Loss: 1.1620\n",
      "Epoch [10/10], Loss: 0.0210\n",
      "User vector from hidden layer: tensor([[ 0.3591,  0.0000,  1.6366,  0.5369,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         10.6264,  0.4246,  0.2583,  0.0000,  0.0000,  0.5845,  0.1144,  3.5070,\n",
      "          0.0000,  0.0430,  0.0000,  0.0000,  3.4792,  3.2731,  0.3296,  0.3803,\n",
      "          1.0154,  0.4255,  0.0000,  0.0257,  0.7121,  1.0507,  0.0000,  1.3996,\n",
      "          0.0000,  0.0651,  0.0000,  0.0000,  5.8750,  0.0000,  0.0000,  0.0000,\n",
      "          0.2281,  0.5439,  0.0000,  0.3879,  0.3671,  0.3158,  0.0000,  0.0000,\n",
      "          0.0000,  6.7179,  0.7611,  0.4259,  0.1662,  0.7356,  0.0000,  0.4897,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.3409,  5.3575,  0.0000,\n",
      "          0.0000,  0.2504,  0.1535,  0.0000,  0.0000,  0.0000,  3.5666,  0.3998,\n",
      "          1.1071,  0.2330,  3.9513,  0.1180,  2.7047,  0.0000,  0.3135,  0.0000,\n",
      "          0.1813,  2.0725,  0.3093,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.6974,  0.2818,  3.0048,  0.0000,  0.0000,  4.5234,  0.0000,\n",
      "          2.2251,  0.0000,  0.0000,  0.5844,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.5895,  0.0000,  0.0000,  0.4430,  0.0000,  1.7831,  0.0000,  0.0000,\n",
      "          0.4916,  0.0000,  0.1808,  0.6107,  0.4447,  0.0000,  0.0000,  1.5889,\n",
      "          0.0000,  1.2684,  0.0000,  0.0000,  0.0000,  3.1368,  0.0000,  9.2768,\n",
      "          0.0000,  0.6798,  0.2823,  3.4529,  0.0000,  0.0000,  0.5336,  0.0000,\n",
      "          1.1463,  0.0220,  0.0000,  1.5889,  2.1413,  0.0000,  3.2313,  3.1728,\n",
      "          2.3136,  0.0000,  0.1177,  0.0000,  0.0000,  1.6073]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Определяем архитектуру модели\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim1, hidden_dim2, output_dim):\n",
    "        super(MLP, self).__init__()\n",
    "        self.hidden1 = nn.Linear(input_dim, hidden_dim1)\n",
    "        self.hidden2 = nn.Linear(hidden_dim1, hidden_dim2)\n",
    "        self.output = nn.Linear(hidden_dim2, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.hidden1(x))\n",
    "        x = torch.relu(self.hidden2(x))\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "\n",
    "# Параметры модели\n",
    "input_dim = 72  # размерность входных данных\n",
    "hidden_dim1 = 150\n",
    "hidden_dim2 = 300\n",
    "output_dim = 58  # размерность выходных данных (например, для классификации на 3 класса)\n",
    "\n",
    "# Создаем модель\n",
    "model = MLP(input_dim, hidden_dim1, hidden_dim2, output_dim)\n",
    "\n",
    "# Определяем функцию потерь и оптимизатор\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Обучение модели (пример)\n",
    "def train(model, data_loader, criterion, optimizer, epochs=10):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        for inputs, labels in data_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# Извлечение векторов из скрытого слоя\n",
    "def get_hidden_vectors(model, inputs):\n",
    "    with torch.no_grad():\n",
    "        hidden_layer_output = torch.relu(model.hidden1(inputs))\n",
    "        return hidden_layer_output\n",
    "\n",
    "train(model, data_loader, criterion, optimizer)\n",
    "\n",
    "# Получение вектора пользователя\n",
    "user_data = torch.randn(1, input_dim)  # пример входных данных для одного пользователя\n",
    "user_vector = get_hidden_vectors(model, user_data)\n",
    "print(\"User vector from hidden layer:\", user_vector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "id": "ea39207b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_val = CustomDataset(X_val, target_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "id": "5b2e9811",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6983, 73)"
      ]
     },
     "execution_count": 594,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "id": "b5aef742",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем экземпляр Dataset для тестовых данных\n",
    "val_dataset = CustomDataset(X_val, target_column)\n",
    "\n",
    "# Создаем DataLoader для тестовых данных\n",
    "val_loader = DataLoader(val_dataset, batch_size=2, shuffle=False)\n",
    "\n",
    "# Применяем модель к тестовым данным\n",
    "model.eval()  # Устанавливаем модель в режим оценки\n",
    "\n",
    "y_val_pred = []\n",
    "with torch.no_grad():  # Отключаем градиенты для тестирования\n",
    "    for inputs, labels in val_loader:\n",
    "        outputs = model(inputs)  # Применяем модель к входным данным\n",
    "        _, predicted = torch.max(outputs, 1)  # Получаем индексы максимальных значений\n",
    "        y_val_pred.extend(predicted.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "id": "40bf3715",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6983"
      ]
     },
     "execution_count": 596,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_loader.dataset.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "id": "0d4661f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Делаем валидацию нашей модель\n",
    "y_val_word = pd.DataFrame()\n",
    "\n",
    "\n",
    "y_val_word['word'] = 'user_' + y_val.astype(str) \n",
    "\n",
    "y_val_word['true'] = y_val\n",
    "\n",
    "y_val_word['preds'] = y_val_pred\n",
    "\n",
    "y_val_pred_word = pd.DataFrame(y_val_word.groupby('word')[['true','preds']].agg(lambda x: x.value_counts().index[0]))\n",
    "\n",
    "y_val_pred_word['comp'] = y_val_pred_word['preds'] == y_val_pred_word['true']\n",
    "\n",
    "y_val_pred_word['norm'] = 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7245af",
   "metadata": {},
   "source": [
    "### Оцениваем качество"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "e807fdf7-d115-43d7-b1b4-ad0e9545c526",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Делаем валидацию нашей модель\n",
    "\n",
    "# Создаем новые датасеты\n",
    "y_word = pd.DataFrame()\n",
    "y_val_word = pd.DataFrame()\n",
    "\n",
    "\n",
    "# Что типа id в тестовой выборке\n",
    "y_word['word'] = 'user_' + y.astype(str)\n",
    "y_val_word['word'] = 'user_' + y_val.astype(str) \n",
    "\n",
    "# Целевая переменная ground truth\n",
    "y_word['true'] = y\n",
    "y_val_word['true'] = y_val\n",
    "\n",
    "# Добавим предсказания\n",
    "y_word['preds'] = y_pred\n",
    "y_val_word['preds'] = y_val_pred\n",
    "\n",
    "\n",
    "\n",
    "# Делаем датасеты с предсказаниями\n",
    "y_pred_word = pd.DataFrame(y_word.groupby('word')[['true','preds']].agg(lambda x: x.value_counts().index[0]))\n",
    "y_val_pred_word = pd.DataFrame(y_val_word.groupby('word')[['true','preds']].agg(lambda x: x.value_counts().index[0]))\n",
    "\n",
    "# Добавляем сравнение с ground truth\n",
    "y_pred_word['comp'] = y_pred_word['preds'] == y_pred_word['true']\n",
    "y_val_pred_word['comp'] = y_val_pred_word['preds'] == y_val_pred_word['true']\n",
    "\n",
    "\n",
    "# Веса юзеров мы не знаем, давайте возьмем равные веса для простоты = 1. Можно и не брать пролли\n",
    "y_pred_word['norm'] = 1\n",
    "y_val_pred_word['norm'] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "7b7f1106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Оценка train2 38 50 76.0\n"
     ]
    }
   ],
   "source": [
    "# Оцениваем на train\n",
    "\n",
    "true_answers = (y_pred_word['comp'] * y_pred_word['norm']).sum()\n",
    "total_answers = y_pred_word['norm'].sum()\n",
    "precent_true = round((true_answers/total_answers)*100, 1)\n",
    "\n",
    "print('Оценка train2', true_answers, total_answers, precent_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "e40d16e1-e2e5-460b-89b2-4f1005dab98d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Оценка val 14 43 32.6\n"
     ]
    }
   ],
   "source": [
    "# Оцениваем на val\n",
    "\n",
    "true_answers_val = (y_val_pred_word['comp'] * y_val_pred_word['norm']).sum()\n",
    "total_answers_val = y_val_pred_word['norm'].sum()\n",
    "precent_true_val = round((true_answers_val/total_answers_val)*100, 1)\n",
    "\n",
    "print('Оценка val', true_answers_val, total_answers_val, precent_true_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54edd785",
   "metadata": {},
   "source": [
    "### Готовим сабмит"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "fd264328",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = all_data[all_data[\"user_id\"].notna()].shape[0]\n",
    "train_df = all_data[:n]\n",
    "test_df = all_data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "8dddfa3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_df[\"user_id\"].astype(int)\n",
    "X_train = train_df.drop([\"user_id\", \"user_word\", \"ts\"], axis=1)\n",
    "X_test = test_df.drop([\"user_id\", \"user_word\", \"ts\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "1badba0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_X = StandardScaler()\n",
    "scaler_X_test = StandardScaler()\n",
    "\n",
    "X_train = pd.DataFrame(scaler_X.fit_transform(X_train), columns=X_train.columns)\n",
    "X_test = pd.DataFrame(scaler_X_test.fit_transform(X_test), columns=X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "99e095c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = model.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = clf.predict(X_train)\n",
    "\n",
    "y_test_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 908,
   "id": "ae4f0c33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    18\n",
       "1    18\n",
       "2    18\n",
       "3    18\n",
       "4    18\n",
       "Name: user_id, dtype: int32"
      ]
     },
     "execution_count": 908,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 911,
   "id": "218907c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0. , 0.4, 0. , 0.2, 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "        0. , 0. , 0. , 0.3, 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "        0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "        0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "        0. , 0.1, 0. , 0. ],\n",
       "       [0. , 0.2, 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "        0. , 0. , 0. , 0.8, 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "        0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "        0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "        0. , 0. , 0. , 0. ],\n",
       "       [0. , 0.2, 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "        0. , 0. , 0. , 0.8, 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "        0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "        0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "        0. , 0. , 0. , 0. ],\n",
       "       [0. , 0.2, 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "        0. , 0. , 0. , 0.8, 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "        0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "        0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "        0. , 0. , 0. , 0. ],\n",
       "       [0. , 0.2, 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "        0. , 0. , 0. , 0.8, 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "        0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "        0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "        0. , 0. , 0. , 0. ]])"
      ]
     },
     "execution_count": 911,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict_proba(X_train.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "a1227e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_words = pd.DataFrame()\n",
    "\n",
    "test_words['user_word'] = test['user_word']\n",
    "test_words['preds'] = y_test_pred\n",
    "\n",
    "comp_df_test = pd.DataFrame(test_words.groupby('user_word')['preds'].agg(lambda x: x.value_counts().index[0]))\n",
    "\n",
    "comp_df_test.to_csv('answer.csv') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 897,
   "id": "52f31e88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'zip' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "! zip answer.zip answer.csv # Подготовка файла для отправки"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
