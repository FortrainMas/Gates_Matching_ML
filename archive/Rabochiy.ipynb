{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eff0fc81",
   "metadata": {},
   "source": [
    "#### Загружаем данные в all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9075248b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7b8cb16f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37518, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>ts</th>\n",
       "      <th>gate_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18</td>\n",
       "      <td>2022-07-29 09:08:54</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>2022-07-29 09:09:54</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18</td>\n",
       "      <td>2022-07-29 09:09:54</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18</td>\n",
       "      <td>2022-07-29 09:10:06</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>2022-07-29 09:10:08</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                   ts  gate_id\n",
       "0       18  2022-07-29 09:08:54        7\n",
       "1       18  2022-07-29 09:09:54        9\n",
       "2       18  2022-07-29 09:09:54        9\n",
       "3       18  2022-07-29 09:10:06        5\n",
       "4       18  2022-07-29 09:10:08        5"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('data/train.csv', index_col=0)\n",
    "print(train.shape)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f6ccb043",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7125, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ts</th>\n",
       "      <th>gate_id</th>\n",
       "      <th>user_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37518</th>\n",
       "      <td>2023-01-03 08:21:00</td>\n",
       "      <td>9</td>\n",
       "      <td>gini</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37519</th>\n",
       "      <td>2023-01-03 08:21:00</td>\n",
       "      <td>9</td>\n",
       "      <td>gini</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37520</th>\n",
       "      <td>2023-01-03 08:21:18</td>\n",
       "      <td>5</td>\n",
       "      <td>gini</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37521</th>\n",
       "      <td>2023-01-03 08:21:19</td>\n",
       "      <td>5</td>\n",
       "      <td>gini</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37522</th>\n",
       "      <td>2023-01-03 08:21:39</td>\n",
       "      <td>10</td>\n",
       "      <td>gini</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        ts  gate_id user_word\n",
       "37518  2023-01-03 08:21:00        9      gini\n",
       "37519  2023-01-03 08:21:00        9      gini\n",
       "37520  2023-01-03 08:21:18        5      gini\n",
       "37521  2023-01-03 08:21:19        5      gini\n",
       "37522  2023-01-03 08:21:39       10      gini"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('data/test.csv', index_col=0)\n",
    "print(test.shape)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8e32de22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1595994892816343"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data = pd.concat([train, test], axis=0)\n",
    "all_data['ts'] = pd.to_datetime(all_data['ts'])\n",
    "\n",
    "# Доля тест во всей выборке\n",
    "sum(all_data['user_word'].notnull()) / all_data['user_word'].shape[0] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d58c1541",
   "metadata": {},
   "source": [
    "### Графички"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5338de01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "plt.figure()\n",
    "plt.xticks(rotation='vertical')\n",
    "all_data['ts'].hist(bins=50)\n",
    "train['ts'].hist(bins=50)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "12fcfa07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_data[\"gate_id\"].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2566aeff",
   "metadata": {},
   "source": [
    "### Генерируем новые фичи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4d910ac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Only train gates:  0 16\n",
      "Only test gates:  2\n"
     ]
    }
   ],
   "source": [
    "train_gate_list = sorted(list(train['gate_id'].unique()))\n",
    "test_gate_list = sorted(list(test['gate_id'].unique()))\n",
    "\n",
    "only_train = [gate for gate in train_gate_list if gate not in test_gate_list]\n",
    "only_test = [gate for gate in test_gate_list if gate not in train_gate_list]\n",
    "\n",
    "print(\"Only train gates: \", \" \".join(map(str, only_train)))\n",
    "print(\"Only test gates: \", \" \".join(map(str, only_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "97146f5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>ts</th>\n",
       "      <th>gate_id</th>\n",
       "      <th>user_word</th>\n",
       "      <th>gate_-1</th>\n",
       "      <th>gate_0</th>\n",
       "      <th>gate_1</th>\n",
       "      <th>gate_2</th>\n",
       "      <th>gate_3</th>\n",
       "      <th>gate_4</th>\n",
       "      <th>...</th>\n",
       "      <th>gate_7</th>\n",
       "      <th>gate_8</th>\n",
       "      <th>gate_9</th>\n",
       "      <th>gate_10</th>\n",
       "      <th>gate_11</th>\n",
       "      <th>gate_12</th>\n",
       "      <th>gate_13</th>\n",
       "      <th>gate_14</th>\n",
       "      <th>gate_15</th>\n",
       "      <th>gate_16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>2022-07-29 09:08:54</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                  ts  gate_id user_word  gate_-1  gate_0  gate_1  \\\n",
       "0     18.0 2022-07-29 09:08:54        7       NaN    False   False   False   \n",
       "\n",
       "   gate_2  gate_3  gate_4  ...  gate_7  gate_8  gate_9  gate_10  gate_11  \\\n",
       "0   False   False   False  ...    True   False   False    False    False   \n",
       "\n",
       "   gate_12  gate_13  gate_14  gate_15  gate_16  \n",
       "0    False    False    False    False    False  \n",
       "\n",
       "[1 rows x 22 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1st transformation\n",
    "#Adding dummies for gates\n",
    "\n",
    "gates = pd.get_dummies(all_data['gate_id'])\n",
    "gates.columns = [\"gate_\" + str(col) for col in gates.columns]\n",
    "all_data = pd.concat([all_data, gates], axis=1)\n",
    "\n",
    "all_data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "818d1286",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2nd transformation\n",
    "#Adding dummies for days of week\n",
    "\n",
    "\n",
    "days_of_week = [\"Monday\",\"Tuesday\",\"Wednesday\",\"Thursday\",\"Friday\",\"Saturday\",\"Sunday\"]\n",
    "all_data[days_of_week] = pd.get_dummies(all_data['ts'].dt.day_name())[days_of_week]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2017a0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3rd transformation\n",
    "#Time\n",
    "\n",
    "all_data['hour'] = all_data['ts'].dt.hour\n",
    "all_data['minute'] = all_data['ts'].dt.minute\n",
    "all_data['day'] = all_data['ts'].dt.day\n",
    "all_data['month'] = all_data['ts'].dt.month\n",
    "\n",
    "\n",
    "hours = pd.get_dummies(all_data['ts'].dt.hour)\n",
    "hours.columns = [\"h_\" + str(col) for col in hours.columns]\n",
    "all_data[hours.columns] = hours[hours.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ef794e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4th transformation\n",
    "# Working and not working days\n",
    "\n",
    "all_data[\"date\"] = all_data[\"ts\"].dt.date\n",
    "count = all_data.groupby(\"date\").size().reset_index(name='count')\n",
    "result = pd.merge(all_data, count, on='date', how='left')\n",
    "\n",
    "result[\"is_weekend\"] = result[\"count\"] < 100\n",
    "result.drop([\"count\", \"date\"], axis=1, inplace=True)\n",
    "\n",
    "all_data = result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b6208785",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5th transformation\n",
    "# Gate n-grams\n",
    "\n",
    "\n",
    "all_data[\"gate_half\"] = all_data[\"gate_id\"] <= 8\n",
    "\n",
    "for i in range(-1, 12):\n",
    "    all_data[\"triplet_\" + str(i+1)] = (all_data[\"gate_id\"] >= i) & (all_data[\"gate_id\"] <= i+2)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1d254340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6th transformation\n",
    "# Estimate working, departure and arrival time\n",
    "\n",
    "\n",
    "# Estimate working, departure and arrival time for train and val\n",
    "stats_train = all_data[all_data.notnull()[\"user_id\"] == True] \\\n",
    "    .groupby([\"user_id\", \"month\", \"day\"]).agg([\"min\", \"max\"])[\"ts\"]\n",
    "stats_train[\"diff\"] = stats_train[\"max\"] - stats_train[\"min\"]\n",
    "stats_train.rename({\"diff\": \"diff_train\", \"min\": \"min_train\", \"max\": \"max_train\"}, axis=1, inplace=True)\n",
    "all_data = pd.merge(all_data, stats_train.reset_index(), how=\"left\", on=[\"user_id\", \"month\", \"day\"])\n",
    "\n",
    "\n",
    "# Estimate working, departure and arrival time for test\n",
    "stats_test = all_data[all_data.notnull()[\"user_id\"] == False] \\\n",
    "    .groupby([\"user_word\", \"month\", \"day\"]).agg([\"min\", \"max\"])[\"ts\"]\n",
    "stats_test[\"diff\"] = stats_test[\"max\"] - stats_test[\"min\"]\n",
    "stats_test.rename({\"diff\": \"diff_test\", \"min\": \"min_test\", \"max\": \"max_test\"}, axis=1, inplace=True)\n",
    "all_data = pd.merge(all_data, stats_test.reset_index(), how=\"left\", on=[\"user_word\", \"month\", \"day\"])\n",
    "\n",
    "\n",
    "# Set unified column name\n",
    "all_data[\"diff\"] = all_data[\"diff_train\"].fillna(all_data[\"diff_test\"])\n",
    "all_data[\"min\"] = all_data[\"min_train\"].fillna(all_data[\"min_test\"])\n",
    "all_data[\"max\"] = all_data[\"max_train\"].fillna(all_data[\"max_test\"])\n",
    "\n",
    "# Drop auxiliary columns\n",
    "all_data.drop([\"min_train\", \"max_train\", \"diff_train\"], axis=1, inplace=True)\n",
    "all_data.drop([\"min_test\", \"max_test\", \"diff_test\"], axis=1, inplace=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c97ef96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7th transformation\n",
    "# Transform times from 6th point\n",
    "all_data[\"diff_hour\"] = all_data[\"diff\"].dt.seconds // 3600\n",
    "all_data[\"diff_min\"] = all_data[\"diff\"].dt.seconds % 3600 // 60\n",
    "\n",
    "all_data[\"arrival_time\"] = all_data[\"min\"].dt.time\n",
    "all_data[\"arrival_hour\"] = all_data[\"min\"].dt.hour\n",
    "all_data[\"arrival_min\"] = all_data[\"min\"].dt.minute\n",
    "\n",
    "all_data[\"departure_time\"] = all_data[\"max\"].dt.time\n",
    "all_data[\"departure_hour\"] = all_data[\"max\"].dt.hour\n",
    "all_data[\"departure_min\"] = all_data[\"max\"].dt.minute\n",
    "\n",
    "all_data.drop([\"diff\", \"min\", \"max\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ef85c05c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# logistic как будто какой-то рандомный тип, который пришел, только один раз\n",
    "# Ему нужно попробовать поставить 999\n",
    "# Ниче не дало\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.countplot(data=all_data[all_data[\"user_word\"] == \"logistic\"], x='arrival_time')\n",
    "\n",
    "plt.xticks(rotation=45)  \n",
    "plt.title('Count of User Arrivals by Time')\n",
    "plt.xlabel('Arrival Time')\n",
    "plt.ylabel('Count')\n",
    "plt.grid(axis='y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4d2ab11a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>ts</th>\n",
       "      <th>gate_id</th>\n",
       "      <th>user_word</th>\n",
       "      <th>gate_-1</th>\n",
       "      <th>gate_0</th>\n",
       "      <th>gate_1</th>\n",
       "      <th>gate_2</th>\n",
       "      <th>gate_3</th>\n",
       "      <th>gate_4</th>\n",
       "      <th>...</th>\n",
       "      <th>triplet_11</th>\n",
       "      <th>triplet_12</th>\n",
       "      <th>diff_hour</th>\n",
       "      <th>diff_min</th>\n",
       "      <th>arrival_time</th>\n",
       "      <th>arrival_hour</th>\n",
       "      <th>arrival_min</th>\n",
       "      <th>departure_time</th>\n",
       "      <th>departure_hour</th>\n",
       "      <th>departure_min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37670</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-01-03 15:42:45</td>\n",
       "      <td>5</td>\n",
       "      <td>logistic</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>15:42:45</td>\n",
       "      <td>15</td>\n",
       "      <td>42</td>\n",
       "      <td>16:59:20</td>\n",
       "      <td>16</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37672</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-01-03 15:42:47</td>\n",
       "      <td>5</td>\n",
       "      <td>logistic</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>15:42:45</td>\n",
       "      <td>15</td>\n",
       "      <td>42</td>\n",
       "      <td>16:59:20</td>\n",
       "      <td>16</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37681</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-01-03 16:58:47</td>\n",
       "      <td>11</td>\n",
       "      <td>logistic</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>15:42:45</td>\n",
       "      <td>15</td>\n",
       "      <td>42</td>\n",
       "      <td>16:59:20</td>\n",
       "      <td>16</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37682</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-01-03 16:59:18</td>\n",
       "      <td>4</td>\n",
       "      <td>logistic</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>15:42:45</td>\n",
       "      <td>15</td>\n",
       "      <td>42</td>\n",
       "      <td>16:59:20</td>\n",
       "      <td>16</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37683</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-01-03 16:59:20</td>\n",
       "      <td>4</td>\n",
       "      <td>logistic</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>15:42:45</td>\n",
       "      <td>15</td>\n",
       "      <td>42</td>\n",
       "      <td>16:59:20</td>\n",
       "      <td>16</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 77 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id                  ts  gate_id user_word  gate_-1  gate_0  \\\n",
       "37670      NaN 2023-01-03 15:42:45        5  logistic    False   False   \n",
       "37672      NaN 2023-01-03 15:42:47        5  logistic    False   False   \n",
       "37681      NaN 2023-01-03 16:58:47       11  logistic    False   False   \n",
       "37682      NaN 2023-01-03 16:59:18        4  logistic    False   False   \n",
       "37683      NaN 2023-01-03 16:59:20        4  logistic    False   False   \n",
       "\n",
       "       gate_1  gate_2  gate_3  gate_4  ...  triplet_11  triplet_12  diff_hour  \\\n",
       "37670   False   False   False   False  ...       False       False          1   \n",
       "37672   False   False   False   False  ...       False       False          1   \n",
       "37681   False   False   False   False  ...        True        True          1   \n",
       "37682   False   False   False    True  ...       False       False          1   \n",
       "37683   False   False   False    True  ...       False       False          1   \n",
       "\n",
       "       diff_min  arrival_time  arrival_hour  arrival_min  departure_time  \\\n",
       "37670        16      15:42:45            15           42        16:59:20   \n",
       "37672        16      15:42:45            15           42        16:59:20   \n",
       "37681        16      15:42:45            15           42        16:59:20   \n",
       "37682        16      15:42:45            15           42        16:59:20   \n",
       "37683        16      15:42:45            15           42        16:59:20   \n",
       "\n",
       "       departure_hour  departure_min  \n",
       "37670              16             59  \n",
       "37672              16             59  \n",
       "37681              16             59  \n",
       "37682              16             59  \n",
       "37683              16             59  \n",
       "\n",
       "[5 rows x 77 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data[all_data[\"user_word\"] == \"logistic\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c631fe79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "# Создаем функции для вычисления среднего времени\n",
    "def time_to_seconds(t):\n",
    "    return t.hour * 3600 + t.minute * 60 + t.second\n",
    "\n",
    "def seconds_to_time(s):\n",
    "    return pd.to_timedelta(s, unit='s')\n",
    "\n",
    "test_data = all_data[all_data[\"user_word\"].isna() == False].groupby([\"user_word\"]).agg(\n",
    "        average_arrival_test=('arrival_time', lambda x: seconds_to_time(np.mean([time_to_seconds(t) for t in x]))),\n",
    "        std_arrival_test=('arrival_time', lambda x: seconds_to_time(np.std([time_to_seconds(t) for t in x]))),\n",
    "        average_departure_test=('departure_time', lambda x: seconds_to_time(np.mean([time_to_seconds(t) for t in x]))),\n",
    "        std_departure_test=('departure_time', lambda x: seconds_to_time(np.std([time_to_seconds(t) for t in x])))\n",
    "    )\n",
    "\n",
    "train_data = all_data[all_data[\"user_word\"].isna()].groupby([\"user_id\"]).agg(\n",
    "        average_arrival_train=('arrival_time', lambda x: seconds_to_time(np.mean([time_to_seconds(t) for t in x]))),\n",
    "        std_arrival_train=('arrival_time', lambda x: seconds_to_time(np.std([time_to_seconds(t) for t in x]))),\n",
    "        average_departure_train=('departure_time', lambda x: seconds_to_time(np.mean([time_to_seconds(t) for t in x]))),\n",
    "        std_departure_train=('departure_time', lambda x: seconds_to_time(np.std([time_to_seconds(t) for t in x])))\n",
    "    )\n",
    "\n",
    "\n",
    "all_data = pd.merge(all_data, test_data.reset_index(), how=\"left\", on=[\"user_word\"])\n",
    "all_data = pd.merge(all_data, train_data.reset_index(), how=\"left\", on=[\"user_id\"])\n",
    "\n",
    "all_data[\"average_arrival\"] = (all_data[\"average_arrival_test\"].fillna(all_data[\"average_arrival_train\"]))\n",
    "all_data[\"std_arrival\"] = all_data[\"std_arrival_test\"].fillna(all_data[\"std_arrival_train\"])\n",
    "all_data[\"average_departure\"] = all_data[\"average_departure_test\"].fillna(all_data[\"average_departure_train\"])\n",
    "all_data[\"std_departure\"] = all_data[\"std_departure_test\"].fillna(all_data[\"std_departure_train\"])\n",
    "all_data.drop([\"average_arrival_test\", \"average_arrival_train\", \"std_arrival_test\", \"std_arrival_train\", \"average_departure_test\", \"average_departure_train\", \"std_departure_test\", \"std_departure_train\"], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "all_data[\"average_arrival\"] = all_data[\"average_arrival\"].dt.seconds // 60\n",
    "all_data[\"std_arrival\"] = all_data[\"std_arrival\"].dt.seconds // 60\n",
    "\n",
    "all_data[\"average_departure\"] = all_data[\"average_departure\"].dt.seconds // 60\n",
    "all_data[\"std_departure\"] = all_data[\"std_departure\"].dt.seconds // 60\n",
    "\n",
    "all_data.drop([\"arrival_time\", \"departure_time\"], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "30b07ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8th transformation\n",
    "# Gates number\n",
    "\n",
    "\n",
    "all_data['count_train'] = all_data.groupby(['user_id', 'month', 'day'])['ts'].transform('count')\n",
    "all_data['count_test'] = all_data.groupby(['user_word', 'month', 'day'])['ts'].transform('count')\n",
    "all_data['gates_today'] = all_data['count_train'].fillna(all_data['count_test'])\n",
    "all_data.drop(['count_train', 'count_test'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "forsomereason = all_data.groupby(['user_id'])['gates_today'].agg([\"mean\", \"std\"])\n",
    "forsomereason.rename({\"mean\": \"mean_train\", \"std\": \"std_train\"}, axis=1, inplace=True)\n",
    "all_data = pd.merge(all_data, forsomereason, on=\"user_id\", how=\"left\")\n",
    "\n",
    "forsomereason = all_data.groupby(['user_word'])['gates_today'].agg([\"mean\", \"std\"])\n",
    "forsomereason.rename({\"mean\": \"mean_test\", \"std\": \"std_test\"}, axis=1, inplace=True)\n",
    "all_data = pd.merge(all_data, forsomereason, on=\"user_word\", how=\"left\")\n",
    "all_data[\"gates_avg\"] = all_data[\"mean_train\"].fillna(all_data[\"mean_test\"])\n",
    "all_data[\"gates_std\"] = all_data[\"std_train\"].fillna(all_data[\"std_test\"])\n",
    "all_data.drop(['mean_train', 'mean_test', \"std_test\", \"std_train\"], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9c35854c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>ts</th>\n",
       "      <th>gate_id</th>\n",
       "      <th>user_word</th>\n",
       "      <th>gate_-1</th>\n",
       "      <th>gate_0</th>\n",
       "      <th>gate_1</th>\n",
       "      <th>gate_2</th>\n",
       "      <th>gate_3</th>\n",
       "      <th>gate_4</th>\n",
       "      <th>...</th>\n",
       "      <th>arrival_min</th>\n",
       "      <th>departure_hour</th>\n",
       "      <th>departure_min</th>\n",
       "      <th>average_arrival</th>\n",
       "      <th>std_arrival</th>\n",
       "      <th>average_departure</th>\n",
       "      <th>std_departure</th>\n",
       "      <th>gates_today</th>\n",
       "      <th>gates_avg</th>\n",
       "      <th>gates_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>2022-07-29 09:08:54</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "      <td>41</td>\n",
       "      <td>574</td>\n",
       "      <td>91</td>\n",
       "      <td>1132</td>\n",
       "      <td>96</td>\n",
       "      <td>58.0</td>\n",
       "      <td>27.782003</td>\n",
       "      <td>10.251158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18.0</td>\n",
       "      <td>2022-07-29 09:09:54</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "      <td>41</td>\n",
       "      <td>574</td>\n",
       "      <td>91</td>\n",
       "      <td>1132</td>\n",
       "      <td>96</td>\n",
       "      <td>58.0</td>\n",
       "      <td>27.782003</td>\n",
       "      <td>10.251158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.0</td>\n",
       "      <td>2022-07-29 09:09:54</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "      <td>41</td>\n",
       "      <td>574</td>\n",
       "      <td>91</td>\n",
       "      <td>1132</td>\n",
       "      <td>96</td>\n",
       "      <td>58.0</td>\n",
       "      <td>27.782003</td>\n",
       "      <td>10.251158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18.0</td>\n",
       "      <td>2022-07-29 09:10:06</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "      <td>41</td>\n",
       "      <td>574</td>\n",
       "      <td>91</td>\n",
       "      <td>1132</td>\n",
       "      <td>96</td>\n",
       "      <td>58.0</td>\n",
       "      <td>27.782003</td>\n",
       "      <td>10.251158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18.0</td>\n",
       "      <td>2022-07-29 09:10:08</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "      <td>41</td>\n",
       "      <td>574</td>\n",
       "      <td>91</td>\n",
       "      <td>1132</td>\n",
       "      <td>96</td>\n",
       "      <td>58.0</td>\n",
       "      <td>27.782003</td>\n",
       "      <td>10.251158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44638</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-02-24 19:43:36</td>\n",
       "      <td>11</td>\n",
       "      <td>collinear</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>19</td>\n",
       "      <td>44</td>\n",
       "      <td>746</td>\n",
       "      <td>179</td>\n",
       "      <td>1168</td>\n",
       "      <td>125</td>\n",
       "      <td>13.0</td>\n",
       "      <td>15.316109</td>\n",
       "      <td>6.864349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44639</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-02-24 19:44:00</td>\n",
       "      <td>4</td>\n",
       "      <td>collinear</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>19</td>\n",
       "      <td>44</td>\n",
       "      <td>746</td>\n",
       "      <td>179</td>\n",
       "      <td>1168</td>\n",
       "      <td>125</td>\n",
       "      <td>13.0</td>\n",
       "      <td>15.316109</td>\n",
       "      <td>6.864349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44640</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-02-24 19:44:01</td>\n",
       "      <td>4</td>\n",
       "      <td>collinear</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>19</td>\n",
       "      <td>44</td>\n",
       "      <td>746</td>\n",
       "      <td>179</td>\n",
       "      <td>1168</td>\n",
       "      <td>125</td>\n",
       "      <td>13.0</td>\n",
       "      <td>15.316109</td>\n",
       "      <td>6.864349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44641</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-02-24 19:44:09</td>\n",
       "      <td>9</td>\n",
       "      <td>collinear</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>19</td>\n",
       "      <td>44</td>\n",
       "      <td>746</td>\n",
       "      <td>179</td>\n",
       "      <td>1168</td>\n",
       "      <td>125</td>\n",
       "      <td>13.0</td>\n",
       "      <td>15.316109</td>\n",
       "      <td>6.864349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44642</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-02-24 19:44:09</td>\n",
       "      <td>9</td>\n",
       "      <td>collinear</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>19</td>\n",
       "      <td>44</td>\n",
       "      <td>746</td>\n",
       "      <td>179</td>\n",
       "      <td>1168</td>\n",
       "      <td>125</td>\n",
       "      <td>13.0</td>\n",
       "      <td>15.316109</td>\n",
       "      <td>6.864349</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>44643 rows × 82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id                  ts  gate_id  user_word  gate_-1  gate_0  \\\n",
       "0         18.0 2022-07-29 09:08:54        7        NaN    False   False   \n",
       "1         18.0 2022-07-29 09:09:54        9        NaN    False   False   \n",
       "2         18.0 2022-07-29 09:09:54        9        NaN    False   False   \n",
       "3         18.0 2022-07-29 09:10:06        5        NaN    False   False   \n",
       "4         18.0 2022-07-29 09:10:08        5        NaN    False   False   \n",
       "...        ...                 ...      ...        ...      ...     ...   \n",
       "44638      NaN 2023-02-24 19:43:36       11  collinear    False   False   \n",
       "44639      NaN 2023-02-24 19:44:00        4  collinear    False   False   \n",
       "44640      NaN 2023-02-24 19:44:01        4  collinear    False   False   \n",
       "44641      NaN 2023-02-24 19:44:09        9  collinear    False   False   \n",
       "44642      NaN 2023-02-24 19:44:09        9  collinear    False   False   \n",
       "\n",
       "       gate_1  gate_2  gate_3  gate_4  ...  arrival_min  departure_hour  \\\n",
       "0       False   False   False   False  ...            8              18   \n",
       "1       False   False   False   False  ...            8              18   \n",
       "2       False   False   False   False  ...            8              18   \n",
       "3       False   False   False   False  ...            8              18   \n",
       "4       False   False   False   False  ...            8              18   \n",
       "...       ...     ...     ...     ...  ...          ...             ...   \n",
       "44638   False   False   False   False  ...           12              19   \n",
       "44639   False   False   False    True  ...           12              19   \n",
       "44640   False   False   False    True  ...           12              19   \n",
       "44641   False   False   False   False  ...           12              19   \n",
       "44642   False   False   False   False  ...           12              19   \n",
       "\n",
       "       departure_min  average_arrival  std_arrival  average_departure  \\\n",
       "0                 41              574           91               1132   \n",
       "1                 41              574           91               1132   \n",
       "2                 41              574           91               1132   \n",
       "3                 41              574           91               1132   \n",
       "4                 41              574           91               1132   \n",
       "...              ...              ...          ...                ...   \n",
       "44638             44              746          179               1168   \n",
       "44639             44              746          179               1168   \n",
       "44640             44              746          179               1168   \n",
       "44641             44              746          179               1168   \n",
       "44642             44              746          179               1168   \n",
       "\n",
       "       std_departure  gates_today  gates_avg  gates_std  \n",
       "0                 96         58.0  27.782003  10.251158  \n",
       "1                 96         58.0  27.782003  10.251158  \n",
       "2                 96         58.0  27.782003  10.251158  \n",
       "3                 96         58.0  27.782003  10.251158  \n",
       "4                 96         58.0  27.782003  10.251158  \n",
       "...              ...          ...        ...        ...  \n",
       "44638            125         13.0  15.316109   6.864349  \n",
       "44639            125         13.0  15.316109   6.864349  \n",
       "44640            125         13.0  15.316109   6.864349  \n",
       "44641            125         13.0  15.316109   6.864349  \n",
       "44642            125         13.0  15.316109   6.864349  \n",
       "\n",
       "[44643 rows x 82 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "43f768ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9th transformation\n",
    "# Adding noise\n",
    "\n",
    "noise_average = 20\n",
    "all_data[\"average_arrival\"] = all_data[\"average_arrival\"] + np.random.normal(0, noise_average, len(all_data))\n",
    "all_data[\"average_departure\"] = all_data[\"average_departure\"] + np.random.normal(0, noise_average, len(all_data))\n",
    "\n",
    "noise_std = 2\n",
    "all_data[\"std_arrival\"] = all_data[\"std_arrival\"] + np.random.normal(0, noise_std, len(all_data))\n",
    "all_data[\"std_departure\"] = all_data[\"std_departure\"] + np.random.normal(0, noise_std, len(all_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "e322bbbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['user_id', 'ts', 'gate_id', 'user_word', 'gate_-1', 'gate_0', 'gate_1',\n",
      "       'gate_2', 'gate_3', 'gate_4', 'gate_5', 'gate_6', 'gate_7', 'gate_8',\n",
      "       'gate_9', 'gate_10', 'gate_11', 'gate_12', 'gate_13', 'gate_14',\n",
      "       'gate_15', 'gate_16', 'Monday', 'Tuesday', 'Wednesday', 'Thursday',\n",
      "       'Friday', 'Saturday', 'Sunday', 'hour', 'minute', 'day', 'month', 'h_0',\n",
      "       'h_1', 'h_3', 'h_6', 'h_7', 'h_8', 'h_9', 'h_10', 'h_11', 'h_12',\n",
      "       'h_13', 'h_14', 'h_15', 'h_16', 'h_17', 'h_18', 'h_19', 'h_20', 'h_21',\n",
      "       'h_22', 'h_23', 'is_weekend', 'gate_half', 'triplet_0', 'triplet_1',\n",
      "       'triplet_2', 'triplet_3', 'triplet_4', 'triplet_5', 'triplet_6',\n",
      "       'triplet_7', 'triplet_8', 'triplet_9', 'triplet_10', 'triplet_11',\n",
      "       'triplet_12', 'diff_hour', 'diff_min', 'arrival_hour', 'arrival_min',\n",
      "       'departure_hour', 'departure_min', 'average_arrival', 'std_arrival',\n",
      "       'average_departure', 'std_departure', 'gates_today', 'gates_avg',\n",
      "       'gates_std'],\n",
      "      dtype='object') 82\n"
     ]
    }
   ],
   "source": [
    "print(all_data.columns, len(all_data.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "298b9b31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "max      2022-12-31 20:39:31\n",
       "count                  37518\n",
       "Name: ts, dtype: object"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['ts'].agg(['max','count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "e7e72539",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "min      2023-01-03 08:21:00\n",
       "max      2023-02-24 19:44:09\n",
       "count                   7125\n",
       "Name: ts, dtype: object"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['ts'].agg(['min','max','count'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460f84ec",
   "metadata": {},
   "source": [
    "### Подготовить трэйн и валидацию\n",
    "\n",
    "В результате получается два датафрейма.\n",
    "- train - записи с начала до 30 ноября\n",
    "- validation - записи с 30 ноября до 31 декабря"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0dfd2c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подготовим данные для train, test\n",
    "\n",
    "train_idx = all_data['user_word'].isnull()\n",
    "not_test = all_data[train_idx].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "00b881aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_index = not_test['ts'] > '2022-11-30'\n",
    "\n",
    "train = not_test[~val_index].copy()\n",
    "validation = not_test[val_index].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "9811e80e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((30535, 82), (44643, 82), (6983, 82))"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, all_data.shape, validation.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fffb05f",
   "metadata": {},
   "source": [
    "### Варианты с классическим ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "43191a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "abb2d699",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train[\"user_id\"].astype(int)\n",
    "X = train.drop([\"user_id\", \"user_word\", \"ts\"], axis=1)\n",
    "\n",
    "y_val = validation[\"user_id\"].astype(int)\n",
    "X_val = validation.drop([\"user_id\", \"user_word\", \"ts\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af09a941",
   "metadata": {},
   "source": [
    "##### Scaling (отключен)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c59eba30",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_scale = True\n",
    "\n",
    "\n",
    "if to_scale:\n",
    "    \n",
    "    # Сделаем нормирование \n",
    "    scaler_X = StandardScaler()\n",
    "    scaler_X_val = StandardScaler()\n",
    "    \n",
    "    X = pd.DataFrame(scaler_X.fit_transform(X), columns=X.columns)\n",
    "    X_val = pd.DataFrame(scaler_X_val.fit_transform(X_val), columns=X_val.columns)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d870d954",
   "metadata": {},
   "source": [
    "##### Начинаем обучени\n",
    "Моделька запихивается в переменную model, чтоб потом можно было ее обучить на настоящем train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7db73859",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KNeighborsClassifier(n_neighbors=10, metric='cosine') #104 14\n",
    "# model = CatBoostClassifier(learning_rate=0.001, depth=6, l2_leaf_reg=3, iterations=1000)\n",
    "# model = RandomForestClassifier(n_estimators=100, class_weight='balanced', max_depth=21, criterion='entropy')\n",
    "clf = model.fit(X, y)\n",
    "\n",
    "y_pred = clf.predict(X)\n",
    "\n",
    "y_val_pred = clf.predict(X_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2704c44",
   "metadata": {},
   "source": [
    "##### Избавимся от повторов в ответах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b44e1c4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>true</th>\n",
       "      <th>preds_0</th>\n",
       "      <th>preds_1</th>\n",
       "      <th>preds_2</th>\n",
       "      <th>preds_3</th>\n",
       "      <th>preds_4</th>\n",
       "      <th>preds_5</th>\n",
       "      <th>preds_6</th>\n",
       "      <th>preds_7</th>\n",
       "      <th>preds_8</th>\n",
       "      <th>...</th>\n",
       "      <th>preds_40</th>\n",
       "      <th>preds_41</th>\n",
       "      <th>preds_42</th>\n",
       "      <th>preds_43</th>\n",
       "      <th>preds_44</th>\n",
       "      <th>preds_45</th>\n",
       "      <th>preds_46</th>\n",
       "      <th>preds_47</th>\n",
       "      <th>preds_48</th>\n",
       "      <th>preds_49</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>user_0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.980843</td>\n",
       "      <td>0.002392</td>\n",
       "      <td>0.000188</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000539</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000196</td>\n",
       "      <td>0.001053</td>\n",
       "      <td>0.000513</td>\n",
       "      <td>0.000513</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001461</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.000262</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002190</td>\n",
       "      <td>0.989981</td>\n",
       "      <td>0.000321</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>0.000829</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000171</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000203</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_11</th>\n",
       "      <td>11.0</td>\n",
       "      <td>0.001430</td>\n",
       "      <td>0.000249</td>\n",
       "      <td>0.000260</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000585</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000539</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>0.001098</td>\n",
       "      <td>0.000789</td>\n",
       "      <td>0.000202</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.001216</td>\n",
       "      <td>0.000655</td>\n",
       "      <td>0.001455</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_12</th>\n",
       "      <td>12.0</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000223</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001378</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000224</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000238</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_14</th>\n",
       "      <td>14.0</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.000401</td>\n",
       "      <td>0.000458</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000363</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_15</th>\n",
       "      <td>15.0</td>\n",
       "      <td>0.000248</td>\n",
       "      <td>0.000441</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001628</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001983</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000462</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000480</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000356</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_17</th>\n",
       "      <td>17.0</td>\n",
       "      <td>0.003178</td>\n",
       "      <td>0.000641</td>\n",
       "      <td>0.002449</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000350</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000904</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000671</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.001691</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_18</th>\n",
       "      <td>18.0</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>0.000896</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001047</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000680</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000648</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000226</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000317</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_19</th>\n",
       "      <td>19.0</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002914</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000289</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000778</td>\n",
       "      <td>0.000330</td>\n",
       "      <td>0.000750</td>\n",
       "      <td>0.000254</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000693</td>\n",
       "      <td>0.000172</td>\n",
       "      <td>0.000708</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_20</th>\n",
       "      <td>20.0</td>\n",
       "      <td>0.003304</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004783</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000164</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.001130</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001217</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.006348</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000619</td>\n",
       "      <td>0.003043</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.008174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_22</th>\n",
       "      <td>22.0</td>\n",
       "      <td>0.006988</td>\n",
       "      <td>0.001928</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002169</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000120</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000361</td>\n",
       "      <td>0.006024</td>\n",
       "      <td>0.004337</td>\n",
       "      <td>0.000241</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004578</td>\n",
       "      <td>0.002048</td>\n",
       "      <td>0.001205</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_23</th>\n",
       "      <td>23.0</td>\n",
       "      <td>0.001081</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000721</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000901</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>0.000180</td>\n",
       "      <td>0.003874</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000270</td>\n",
       "      <td>0.002162</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001441</td>\n",
       "      <td>0.000180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_24</th>\n",
       "      <td>24.0</td>\n",
       "      <td>0.001484</td>\n",
       "      <td>0.000273</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000313</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001250</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000117</td>\n",
       "      <td>0.000156</td>\n",
       "      <td>0.001406</td>\n",
       "      <td>0.000195</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000234</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000391</td>\n",
       "      <td>0.000078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_25</th>\n",
       "      <td>25.0</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.000229</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000171</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001029</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.001771</td>\n",
       "      <td>0.000743</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000286</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002343</td>\n",
       "      <td>0.000286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_26</th>\n",
       "      <td>26.0</td>\n",
       "      <td>0.002551</td>\n",
       "      <td>0.000810</td>\n",
       "      <td>0.000364</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002688</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000526</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000578</td>\n",
       "      <td>0.001822</td>\n",
       "      <td>0.000850</td>\n",
       "      <td>0.001255</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001377</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.003647</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_27</th>\n",
       "      <td>27.0</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000166</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>0.000149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_28</th>\n",
       "      <td>28.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001094</td>\n",
       "      <td>0.000313</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006719</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000156</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_29</th>\n",
       "      <td>29.0</td>\n",
       "      <td>0.001621</td>\n",
       "      <td>0.000613</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000865</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000576</td>\n",
       "      <td>0.001211</td>\n",
       "      <td>0.003279</td>\n",
       "      <td>0.000263</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000273</td>\n",
       "      <td>0.000120</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.000203</td>\n",
       "      <td>0.000304</td>\n",
       "      <td>0.992468</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000190</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000987</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000873</td>\n",
       "      <td>0.000127</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.001177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_31</th>\n",
       "      <td>31.0</td>\n",
       "      <td>0.000546</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>0.000785</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000366</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000628</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000262</td>\n",
       "      <td>0.001099</td>\n",
       "      <td>0.000209</td>\n",
       "      <td>0.005936</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>0.001728</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.000419</td>\n",
       "      <td>0.000471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_32</th>\n",
       "      <td>32.0</td>\n",
       "      <td>0.000362</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000899</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000845</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>0.001736</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>0.001747</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000287</td>\n",
       "      <td>0.006485</td>\n",
       "      <td>0.000387</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_33</th>\n",
       "      <td>33.0</td>\n",
       "      <td>0.000487</td>\n",
       "      <td>0.000127</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000156</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000180</td>\n",
       "      <td>0.000461</td>\n",
       "      <td>0.001225</td>\n",
       "      <td>0.000403</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000501</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.001091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_34</th>\n",
       "      <td>34.0</td>\n",
       "      <td>0.001719</td>\n",
       "      <td>0.001769</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006570</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000289</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000975</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>0.002022</td>\n",
       "      <td>0.000253</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002310</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001155</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_35</th>\n",
       "      <td>35.0</td>\n",
       "      <td>0.000625</td>\n",
       "      <td>0.000404</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001885</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003679</td>\n",
       "      <td>0.000221</td>\n",
       "      <td>0.010625</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_36</th>\n",
       "      <td>36.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000313</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002812</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000625</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000625</td>\n",
       "      <td>0.003438</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000313</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010313</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_37</th>\n",
       "      <td>37.0</td>\n",
       "      <td>0.000856</td>\n",
       "      <td>0.000167</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006011</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000651</td>\n",
       "      <td>0.000348</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002767</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.001199</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_38</th>\n",
       "      <td>38.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003077</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001538</td>\n",
       "      <td>0.002308</td>\n",
       "      <td>0.003846</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000769</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002308</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006154</td>\n",
       "      <td>0.003077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_39</th>\n",
       "      <td>39.0</td>\n",
       "      <td>0.002709</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001038</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000323</td>\n",
       "      <td>0.001453</td>\n",
       "      <td>0.001930</td>\n",
       "      <td>0.000964</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.000462</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_40</th>\n",
       "      <td>40.0</td>\n",
       "      <td>0.000413</td>\n",
       "      <td>0.000124</td>\n",
       "      <td>0.000289</td>\n",
       "      <td>0.000124</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000331</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000372</td>\n",
       "      <td>0.001240</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000165</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004711</td>\n",
       "      <td>0.000909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_41</th>\n",
       "      <td>41.0</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.001342</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002095</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004063</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002188</td>\n",
       "      <td>0.002188</td>\n",
       "      <td>0.003438</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019375</td>\n",
       "      <td>0.000937</td>\n",
       "      <td>0.002188</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_42</th>\n",
       "      <td>42.0</td>\n",
       "      <td>0.001226</td>\n",
       "      <td>0.001560</td>\n",
       "      <td>0.001031</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000167</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.000641</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>0.001198</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>0.000334</td>\n",
       "      <td>0.000864</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_43</th>\n",
       "      <td>43.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.036667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_45</th>\n",
       "      <td>45.0</td>\n",
       "      <td>0.001404</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>0.000526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000526</td>\n",
       "      <td>0.001579</td>\n",
       "      <td>0.000526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001053</td>\n",
       "      <td>0.000351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_46</th>\n",
       "      <td>46.0</td>\n",
       "      <td>0.000391</td>\n",
       "      <td>0.000168</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000223</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000704</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.000866</td>\n",
       "      <td>0.000363</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000726</td>\n",
       "      <td>0.000196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_47</th>\n",
       "      <td>47.0</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002283</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>...</td>\n",
       "      <td>0.985940</td>\n",
       "      <td>0.000117</td>\n",
       "      <td>0.001663</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000799</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000180</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_48</th>\n",
       "      <td>48.0</td>\n",
       "      <td>0.001339</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000607</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000203</td>\n",
       "      <td>0.981620</td>\n",
       "      <td>0.000378</td>\n",
       "      <td>0.000918</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000688</td>\n",
       "      <td>0.002584</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_49</th>\n",
       "      <td>49.0</td>\n",
       "      <td>0.000410</td>\n",
       "      <td>0.000677</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001017</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001828</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>0.981649</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000369</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_5</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_50</th>\n",
       "      <td>50.0</td>\n",
       "      <td>0.001066</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.001007</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000225</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000983</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.001114</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>0.982095</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000308</td>\n",
       "      <td>0.002998</td>\n",
       "      <td>0.000213</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>0.001341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_52</th>\n",
       "      <td>52.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006000</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_53</th>\n",
       "      <td>53.0</td>\n",
       "      <td>0.000863</td>\n",
       "      <td>0.000321</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004079</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000481</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000682</td>\n",
       "      <td>0.000367</td>\n",
       "      <td>0.000352</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.981401</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.002013</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_54</th>\n",
       "      <td>54.0</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000676</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.002125</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>0.002767</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000243</td>\n",
       "      <td>0.981927</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_55</th>\n",
       "      <td>55.0</td>\n",
       "      <td>0.000173</td>\n",
       "      <td>0.000292</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001016</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>0.000137</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001676</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.990755</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_56</th>\n",
       "      <td>56.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000220</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000220</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000110</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000549</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000549</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000440</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.963297</td>\n",
       "      <td>0.000220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_57</th>\n",
       "      <td>57.0</td>\n",
       "      <td>0.001851</td>\n",
       "      <td>0.001066</td>\n",
       "      <td>0.001751</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000121</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000644</td>\n",
       "      <td>0.000463</td>\n",
       "      <td>0.002865</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000689</td>\n",
       "      <td>0.001610</td>\n",
       "      <td>0.000402</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.975355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_6</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.000269</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.978461</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001812</td>\n",
       "      <td>0.000233</td>\n",
       "      <td>0.000628</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002961</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.000688</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_7</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001837</td>\n",
       "      <td>0.000204</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.987143</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000204</td>\n",
       "      <td>0.000204</td>\n",
       "      <td>0.000612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_8</th>\n",
       "      <td>8.0</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.974483</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001034</td>\n",
       "      <td>0.000690</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_9</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.000292</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000247</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.992720</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>0.000529</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000717</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.000247</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000067</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         true   preds_0   preds_1   preds_2   preds_3   preds_4   preds_5  \\\n",
       "word                                                                        \n",
       "user_0    0.0  0.980843  0.002392  0.000188  0.000000  0.000000  0.000539   \n",
       "user_1    1.0  0.002190  0.989981  0.000321  0.000000  0.000000  0.000122   \n",
       "user_11  11.0  0.001430  0.000249  0.000260  0.000000  0.000000  0.000585   \n",
       "user_12  12.0  0.000079  0.000086  0.000006  0.000000  0.000000  0.000223   \n",
       "user_14  14.0  0.000038  0.000000  0.000095  0.000000  0.000000  0.000134   \n",
       "user_15  15.0  0.000248  0.000441  0.000013  0.000000  0.000000  0.001628   \n",
       "user_17  17.0  0.003178  0.000641  0.002449  0.000000  0.000000  0.000058   \n",
       "user_18  18.0  0.000063  0.000896  0.000019  0.000000  0.000000  0.001047   \n",
       "user_19  19.0  0.000096  0.000028  0.000000  0.000000  0.000000  0.002914   \n",
       "user_20  20.0  0.003304  0.000000  0.004783  0.000000  0.000000  0.000164   \n",
       "user_22  22.0  0.006988  0.001928  0.000000  0.000000  0.000000  0.002169   \n",
       "user_23  23.0  0.001081  0.000000  0.000721  0.000000  0.000000  0.000000   \n",
       "user_24  24.0  0.001484  0.000273  0.000000  0.000000  0.000000  0.000313   \n",
       "user_25  25.0  0.000457  0.000229  0.000457  0.000057  0.000057  0.000114   \n",
       "user_26  26.0  0.002551  0.000810  0.000364  0.000000  0.000000  0.002688   \n",
       "user_27  27.0  0.000017  0.000000  0.000000  0.000000  0.000033  0.000000   \n",
       "user_28  28.0  0.000000  0.000000  0.001094  0.000313  0.000000  0.000000   \n",
       "user_29  29.0  0.001621  0.000613  0.000013  0.000000  0.000000  0.000865   \n",
       "user_3    3.0  0.000203  0.000304  0.992468  0.000000  0.000000  0.000000   \n",
       "user_31  31.0  0.000546  0.000105  0.000785  0.000052  0.000000  0.000366   \n",
       "user_32  32.0  0.000362  0.000000  0.000899  0.000000  0.000000  0.000216   \n",
       "user_33  33.0  0.000487  0.000127  0.000053  0.000000  0.000000  0.000286   \n",
       "user_34  34.0  0.001719  0.001769  0.000036  0.000072  0.000000  0.006570   \n",
       "user_35  35.0  0.000625  0.000404  0.000000  0.000000  0.000000  0.001885   \n",
       "user_36  36.0  0.000000  0.000000  0.000000  0.000000  0.000313  0.000000   \n",
       "user_37  37.0  0.000856  0.000167  0.000000  0.000000  0.000000  0.006011   \n",
       "user_38  38.0  0.000000  0.000000  0.003077  0.000000  0.000000  0.000000   \n",
       "user_39  39.0  0.002709  0.000111  0.000058  0.000000  0.000000  0.001038   \n",
       "user_4    4.0  0.000000  0.000000  0.000000  0.930000  0.000000  0.000000   \n",
       "user_40  40.0  0.000413  0.000124  0.000289  0.000124  0.000000  0.000000   \n",
       "user_41  41.0  0.005000  0.001342  0.000000  0.000000  0.000000  0.002095   \n",
       "user_42  42.0  0.001226  0.001560  0.001031  0.000000  0.000000  0.000167   \n",
       "user_43  43.0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "user_45  45.0  0.001404  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "user_46  46.0  0.000391  0.000168  0.000084  0.000056  0.000084  0.000112   \n",
       "user_47  47.0  0.000149  0.000037  0.000000  0.000000  0.000000  0.002283   \n",
       "user_48  48.0  0.001339  0.000027  0.000108  0.000000  0.000000  0.000607   \n",
       "user_49  49.0  0.000410  0.000677  0.000019  0.000000  0.000000  0.001017   \n",
       "user_5    5.0  0.000000  0.000000  0.000000  0.000000  0.910000  0.000000   \n",
       "user_50  50.0  0.001066  0.000036  0.001007  0.000000  0.000012  0.000225   \n",
       "user_52  52.0  0.000000  0.000000  0.000000  0.010000  0.002000  0.000000   \n",
       "user_53  53.0  0.000863  0.000321  0.000107  0.000000  0.000000  0.004079   \n",
       "user_54  54.0  0.000133  0.000000  0.000667  0.000000  0.000000  0.000134   \n",
       "user_55  55.0  0.000173  0.000292  0.000031  0.000000  0.000000  0.001016   \n",
       "user_56  56.0  0.000000  0.000000  0.000220  0.000000  0.000220  0.000000   \n",
       "user_57  57.0  0.001851  0.001066  0.001751  0.000000  0.000000  0.000121   \n",
       "user_6    6.0  0.000269  0.000118  0.000006  0.000000  0.000000  0.978461   \n",
       "user_7    7.0  0.000000  0.000000  0.001837  0.000204  0.000000  0.000000   \n",
       "user_8    8.0  0.003448  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "user_9    9.0  0.000292  0.000034  0.000247  0.000000  0.000000  0.000056   \n",
       "\n",
       "          preds_6   preds_7   preds_8  ...  preds_40  preds_41  preds_42  \\\n",
       "word                                   ...                                 \n",
       "user_0   0.000000  0.000063  0.000178  ...  0.000196  0.001053  0.000513   \n",
       "user_1   0.000000  0.000021  0.000054  ...  0.000054  0.000064  0.000829   \n",
       "user_11  0.000000  0.000000  0.000539  ...  0.000077  0.001098  0.000789   \n",
       "user_12  0.000000  0.000018  0.000159  ...  0.001378  0.000000  0.000224   \n",
       "user_14  0.000000  0.000000  0.000057  ...  0.000019  0.000076  0.000401   \n",
       "user_15  0.000000  0.000007  0.000007  ...  0.001983  0.000000  0.000462   \n",
       "user_17  0.000000  0.000000  0.000350  ...  0.000029  0.000904  0.000058   \n",
       "user_18  0.000000  0.000013  0.000013  ...  0.000680  0.000000  0.000648   \n",
       "user_19  0.000000  0.000000  0.000289  ...  0.000778  0.000330  0.000750   \n",
       "user_20  0.000000  0.000087  0.001130  ...  0.000000  0.001217  0.000087   \n",
       "user_22  0.000000  0.000000  0.000120  ...  0.000361  0.006024  0.004337   \n",
       "user_23  0.000000  0.000000  0.000901  ...  0.000090  0.000090  0.000180   \n",
       "user_24  0.000000  0.000000  0.001250  ...  0.000117  0.000156  0.001406   \n",
       "user_25  0.000000  0.000000  0.000171  ...  0.001029  0.000057  0.001771   \n",
       "user_26  0.000000  0.000000  0.000526  ...  0.000578  0.001822  0.000850   \n",
       "user_27  0.000000  0.000017  0.000000  ...  0.000166  0.000017  0.000149   \n",
       "user_28  0.006719  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
       "user_29  0.000000  0.000000  0.000013  ...  0.000576  0.001211  0.003279   \n",
       "user_3   0.000013  0.000000  0.000190  ...  0.000000  0.000038  0.000000   \n",
       "user_31  0.000000  0.000000  0.000628  ...  0.000262  0.001099  0.000209   \n",
       "user_32  0.000000  0.000000  0.000845  ...  0.000107  0.001736  0.000125   \n",
       "user_33  0.000000  0.000000  0.000156  ...  0.000180  0.000461  0.001225   \n",
       "user_34  0.000000  0.000000  0.000289  ...  0.000975  0.000217  0.002022   \n",
       "user_35  0.000000  0.000000  0.000184  ...  0.003679  0.000221  0.010625   \n",
       "user_36  0.000000  0.000000  0.002812  ...  0.000625  0.000000  0.000625   \n",
       "user_37  0.000000  0.000000  0.000016  ...  0.000651  0.000348  0.000181   \n",
       "user_38  0.001538  0.002308  0.003846  ...  0.000000  0.000000  0.000000   \n",
       "user_39  0.000000  0.000000  0.000046  ...  0.000323  0.001453  0.001930   \n",
       "user_4   0.010000  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
       "user_40  0.000041  0.000000  0.000331  ...  0.000083  0.000000  0.000372   \n",
       "user_41  0.000000  0.000000  0.004063  ...  0.002188  0.002188  0.003438   \n",
       "user_42  0.000000  0.000028  0.000641  ...  0.000056  0.000084  0.000084   \n",
       "user_43  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
       "user_45  0.000175  0.000526  0.000000  ...  0.000000  0.000000  0.000526   \n",
       "user_46  0.000028  0.000000  0.000223  ...  0.000704  0.000056  0.000866   \n",
       "user_47  0.000000  0.000000  0.000007  ...  0.985940  0.000117  0.001663   \n",
       "user_48  0.000000  0.000013  0.000189  ...  0.000203  0.981620  0.000378   \n",
       "user_49  0.000000  0.000000  0.000057  ...  0.001828  0.000257  0.981649   \n",
       "user_5   0.000000  0.000000  0.007500  ...  0.000000  0.005000  0.000000   \n",
       "user_50  0.000000  0.000024  0.000983  ...  0.000012  0.001114  0.000071   \n",
       "user_52  0.022000  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
       "user_53  0.000000  0.000000  0.000481  ...  0.000682  0.000367  0.000352   \n",
       "user_54  0.000000  0.000000  0.000676  ...  0.000003  0.002125  0.000158   \n",
       "user_55  0.000000  0.000012  0.000087  ...  0.000177  0.000081  0.000099   \n",
       "user_56  0.000000  0.000000  0.000110  ...  0.000549  0.000000  0.000000   \n",
       "user_57  0.000020  0.000020  0.000060  ...  0.000060  0.000644  0.000463   \n",
       "user_6   0.000000  0.000000  0.000023  ...  0.001812  0.000233  0.000628   \n",
       "user_7   0.987143  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
       "user_8   0.000000  0.974483  0.003448  ...  0.000000  0.000000  0.000000   \n",
       "user_9   0.000000  0.000022  0.992720  ...  0.000022  0.000112  0.000157   \n",
       "\n",
       "         preds_43  preds_44  preds_45  preds_46  preds_47  preds_48  preds_49  \n",
       "word                                                                           \n",
       "user_0   0.000513  0.000000  0.001461  0.000052  0.000262  0.000021  0.000545  \n",
       "user_1   0.000064  0.000000  0.000171  0.000000  0.000203  0.000000  0.000343  \n",
       "user_11  0.000202  0.000010  0.001216  0.000655  0.001455  0.000000  0.000260  \n",
       "user_12  0.000031  0.000000  0.000238  0.000012  0.000000  0.000031  0.000018  \n",
       "user_14  0.000458  0.000000  0.000000  0.000363  0.000095  0.000019  0.000000  \n",
       "user_15  0.000052  0.000000  0.000480  0.000000  0.000356  0.000000  0.000046  \n",
       "user_17  0.000671  0.000000  0.000087  0.000058  0.001691  0.000029  0.000525  \n",
       "user_18  0.000000  0.000000  0.000226  0.000000  0.000317  0.000013  0.000102  \n",
       "user_19  0.000254  0.000000  0.000693  0.000172  0.000708  0.000000  0.000014  \n",
       "user_20  0.006348  0.000000  0.000619  0.003043  0.000000  0.000087  0.008174  \n",
       "user_22  0.000241  0.000000  0.004578  0.002048  0.001205  0.000000  0.001446  \n",
       "user_23  0.003874  0.000000  0.000270  0.002162  0.000000  0.001441  0.000180  \n",
       "user_24  0.000195  0.000000  0.000234  0.000078  0.000000  0.000391  0.000078  \n",
       "user_25  0.000743  0.000000  0.000286  0.000457  0.000000  0.002343  0.000286  \n",
       "user_26  0.001255  0.000000  0.001377  0.000040  0.003647  0.000000  0.000567  \n",
       "user_27  0.000033  0.000000  0.000000  0.000000  0.000000  0.000182  0.000149  \n",
       "user_28  0.000156  0.000000  0.000000  0.000000  0.000000  0.000000  0.000156  \n",
       "user_29  0.000263  0.000000  0.000273  0.000120  0.000063  0.000013  0.000955  \n",
       "user_3   0.000987  0.000000  0.000051  0.000873  0.000127  0.000051  0.001177  \n",
       "user_31  0.005936  0.000000  0.000157  0.001728  0.000052  0.000419  0.000471  \n",
       "user_32  0.001747  0.000000  0.000287  0.006485  0.000387  0.000000  0.000924  \n",
       "user_33  0.000403  0.000000  0.000042  0.000501  0.000032  0.000011  0.001091  \n",
       "user_34  0.000253  0.000000  0.002310  0.000000  0.001155  0.000000  0.000072  \n",
       "user_35  0.000037  0.000000  0.000257  0.000004  0.000257  0.000000  0.000000  \n",
       "user_36  0.003438  0.000000  0.000000  0.000313  0.000000  0.010313  0.000000  \n",
       "user_37  0.000086  0.000000  0.002767  0.000059  0.001199  0.000000  0.000033  \n",
       "user_38  0.000769  0.000000  0.000000  0.002308  0.000000  0.006154  0.003077  \n",
       "user_39  0.000964  0.000000  0.000300  0.000462  0.000046  0.000012  0.000507  \n",
       "user_4   0.010000  0.025000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "user_40  0.001240  0.000000  0.000000  0.000165  0.000000  0.004711  0.000909  \n",
       "user_41  0.000000  0.000000  0.019375  0.000937  0.002188  0.000000  0.000000  \n",
       "user_42  0.001198  0.000000  0.000111  0.000334  0.000864  0.000000  0.000641  \n",
       "user_43  0.036667  0.000000  0.000000  0.008333  0.000000  0.000000  0.000000  \n",
       "user_45  0.001579  0.000526  0.000000  0.000000  0.000000  0.001053  0.000351  \n",
       "user_46  0.000363  0.000112  0.000056  0.000028  0.000000  0.000726  0.000196  \n",
       "user_47  0.000007  0.000000  0.000799  0.000016  0.000180  0.000000  0.000007  \n",
       "user_48  0.000918  0.000000  0.000688  0.002584  0.000216  0.000000  0.000459  \n",
       "user_49  0.000134  0.000000  0.000369  0.000096  0.000105  0.000038  0.000105  \n",
       "user_5   0.000000  0.010000  0.000000  0.000000  0.000000  0.002500  0.010000  \n",
       "user_50  0.982095  0.000000  0.000308  0.002998  0.000213  0.000071  0.001341  \n",
       "user_52  0.006000  0.930000  0.000000  0.000000  0.000000  0.000000  0.004000  \n",
       "user_53  0.000191  0.000000  0.981401  0.000061  0.002013  0.000000  0.000142  \n",
       "user_54  0.002767  0.000000  0.000243  0.981927  0.000085  0.000024  0.000716  \n",
       "user_55  0.000137  0.000000  0.001676  0.000019  0.990755  0.000000  0.000075  \n",
       "user_56  0.000549  0.000000  0.000000  0.000440  0.000000  0.963297  0.000220  \n",
       "user_57  0.002865  0.000000  0.000689  0.001610  0.000402  0.000020  0.975355  \n",
       "user_6   0.000088  0.000000  0.002961  0.000045  0.000688  0.000000  0.000009  \n",
       "user_7   0.000204  0.000204  0.000612  0.000000  0.000000  0.000000  0.000408  \n",
       "user_8   0.001034  0.000690  0.000000  0.000000  0.000000  0.000000  0.000345  \n",
       "user_9   0.000529  0.000000  0.000717  0.000700  0.000247  0.000022  0.000067  \n",
       "\n",
       "[50 rows x 51 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_proba = clf.predict_proba(X)\n",
    "\n",
    "y_word = pd.DataFrame()\n",
    "y_word['word'] = 'user_' + y.astype(str)\n",
    "y_word['true'] = y\n",
    "\n",
    "\n",
    "for i in range(y_pred_proba.shape[1]):\n",
    "    col = y_pred_proba[:,i]\n",
    "    y_word['preds_' + str(i)] = col\n",
    "\n",
    "\n",
    "y_word.groupby([\"word\"]).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 936,
   "id": "8f3247ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true        user_57\n",
       "preds_0      user_0\n",
       "preds_1      user_1\n",
       "preds_2      user_3\n",
       "preds_3      user_4\n",
       "preds_4      user_5\n",
       "preds_5      user_6\n",
       "preds_6      user_7\n",
       "preds_7      user_8\n",
       "preds_8      user_9\n",
       "preds_9     user_11\n",
       "preds_10    user_52\n",
       "preds_11    user_14\n",
       "preds_12    user_15\n",
       "preds_13    user_17\n",
       "preds_14    user_18\n",
       "preds_15    user_19\n",
       "preds_16    user_20\n",
       "preds_17     user_5\n",
       "preds_18    user_23\n",
       "preds_19    user_24\n",
       "preds_20    user_25\n",
       "preds_21    user_26\n",
       "preds_22    user_27\n",
       "preds_23    user_28\n",
       "preds_24    user_29\n",
       "preds_25    user_31\n",
       "preds_26    user_32\n",
       "preds_27    user_33\n",
       "preds_28     user_4\n",
       "preds_29    user_35\n",
       "preds_30    user_36\n",
       "preds_31    user_37\n",
       "preds_32    user_38\n",
       "preds_33    user_39\n",
       "preds_34    user_40\n",
       "preds_35    user_41\n",
       "preds_36    user_42\n",
       "preds_37    user_43\n",
       "preds_38    user_45\n",
       "preds_39    user_46\n",
       "preds_40    user_47\n",
       "preds_41    user_48\n",
       "preds_42    user_49\n",
       "preds_43    user_50\n",
       "preds_44    user_52\n",
       "preds_45    user_53\n",
       "preds_46    user_54\n",
       "preds_47    user_55\n",
       "preds_48    user_56\n",
       "preds_49    user_57\n",
       "dtype: object"
      ]
     },
     "execution_count": 936,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_values = y_word.groupby([\"word\"]).mean().idxmax(axis=0)\n",
    "max_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ada382c",
   "metadata": {},
   "source": [
    "### Нейросетевая попытка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "id": "cebb9798",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.drop([\"ts\", \"user_word\"], axis=1, inplace=True)\n",
    "X_val.drop([\"ts\", \"user_word\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "id": "38dc5686",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 573,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X[\"user_id\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "id": "2ac57c52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0,\n",
       " 1.0,\n",
       " 3.0,\n",
       " 4.0,\n",
       " 5.0,\n",
       " 6.0,\n",
       " 7.0,\n",
       " 8.0,\n",
       " 9.0,\n",
       " 11.0,\n",
       " 12.0,\n",
       " 14.0,\n",
       " 15.0,\n",
       " 17.0,\n",
       " 18.0,\n",
       " 19.0,\n",
       " 20.0,\n",
       " 22.0,\n",
       " 23.0,\n",
       " 24.0,\n",
       " 25.0,\n",
       " 26.0,\n",
       " 27.0,\n",
       " 28.0,\n",
       " 29.0,\n",
       " 31.0,\n",
       " 32.0,\n",
       " 33.0,\n",
       " 34.0,\n",
       " 35.0,\n",
       " 36.0,\n",
       " 37.0,\n",
       " 38.0,\n",
       " 39.0,\n",
       " 40.0,\n",
       " 41.0,\n",
       " 42.0,\n",
       " 43.0,\n",
       " 45.0,\n",
       " 46.0,\n",
       " 47.0,\n",
       " 48.0,\n",
       " 49.0,\n",
       " 50.0,\n",
       " 52.0,\n",
       " 53.0,\n",
       " 54.0,\n",
       " 55.0,\n",
       " 56.0,\n",
       " 57.0]"
      ]
     },
     "execution_count": 577,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(X[\"user_id\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "id": "465ac5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataframe, target_column):\n",
    "        self.dataframe = dataframe\n",
    "        self.target_column = target_column\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Получаем данные и метки\n",
    "        row = self.dataframe.iloc[idx]\n",
    "        features = row.drop(self.target_column).values.astype(float)  # Входные данные\n",
    "        label = row[self.target_column]  # Целевая переменная\n",
    "        \n",
    "        return torch.tensor(features, dtype=torch.float32), torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "\n",
    "# Создаем экземпляр Dataset\n",
    "target_column = 'user_id'\n",
    "dataset = CustomDataset(X, target_column)\n",
    "\n",
    "# Создаем DataLoader\n",
    "data_loader = DataLoader(dataset, batch_size=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f9a8c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "id": "3d78b883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 4.5669\n",
      "Epoch [2/10], Loss: 1.9147\n",
      "Epoch [3/10], Loss: 0.4321\n",
      "Epoch [4/10], Loss: 2.3233\n",
      "Epoch [5/10], Loss: 1.2663\n",
      "Epoch [6/10], Loss: 2.9918\n",
      "Epoch [7/10], Loss: 0.0277\n",
      "Epoch [8/10], Loss: 0.0565\n",
      "Epoch [9/10], Loss: 1.1620\n",
      "Epoch [10/10], Loss: 0.0210\n",
      "User vector from hidden layer: tensor([[ 0.3591,  0.0000,  1.6366,  0.5369,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         10.6264,  0.4246,  0.2583,  0.0000,  0.0000,  0.5845,  0.1144,  3.5070,\n",
      "          0.0000,  0.0430,  0.0000,  0.0000,  3.4792,  3.2731,  0.3296,  0.3803,\n",
      "          1.0154,  0.4255,  0.0000,  0.0257,  0.7121,  1.0507,  0.0000,  1.3996,\n",
      "          0.0000,  0.0651,  0.0000,  0.0000,  5.8750,  0.0000,  0.0000,  0.0000,\n",
      "          0.2281,  0.5439,  0.0000,  0.3879,  0.3671,  0.3158,  0.0000,  0.0000,\n",
      "          0.0000,  6.7179,  0.7611,  0.4259,  0.1662,  0.7356,  0.0000,  0.4897,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.3409,  5.3575,  0.0000,\n",
      "          0.0000,  0.2504,  0.1535,  0.0000,  0.0000,  0.0000,  3.5666,  0.3998,\n",
      "          1.1071,  0.2330,  3.9513,  0.1180,  2.7047,  0.0000,  0.3135,  0.0000,\n",
      "          0.1813,  2.0725,  0.3093,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.6974,  0.2818,  3.0048,  0.0000,  0.0000,  4.5234,  0.0000,\n",
      "          2.2251,  0.0000,  0.0000,  0.5844,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.5895,  0.0000,  0.0000,  0.4430,  0.0000,  1.7831,  0.0000,  0.0000,\n",
      "          0.4916,  0.0000,  0.1808,  0.6107,  0.4447,  0.0000,  0.0000,  1.5889,\n",
      "          0.0000,  1.2684,  0.0000,  0.0000,  0.0000,  3.1368,  0.0000,  9.2768,\n",
      "          0.0000,  0.6798,  0.2823,  3.4529,  0.0000,  0.0000,  0.5336,  0.0000,\n",
      "          1.1463,  0.0220,  0.0000,  1.5889,  2.1413,  0.0000,  3.2313,  3.1728,\n",
      "          2.3136,  0.0000,  0.1177,  0.0000,  0.0000,  1.6073]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Определяем архитектуру модели\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim1, hidden_dim2, output_dim):\n",
    "        super(MLP, self).__init__()\n",
    "        self.hidden1 = nn.Linear(input_dim, hidden_dim1)\n",
    "        self.hidden2 = nn.Linear(hidden_dim1, hidden_dim2)\n",
    "        self.output = nn.Linear(hidden_dim2, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.hidden1(x))\n",
    "        x = torch.relu(self.hidden2(x))\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "\n",
    "# Параметры модели\n",
    "input_dim = 72  # размерность входных данных\n",
    "hidden_dim1 = 150\n",
    "hidden_dim2 = 300\n",
    "output_dim = 58  # размерность выходных данных (например, для классификации на 3 класса)\n",
    "\n",
    "# Создаем модель\n",
    "model = MLP(input_dim, hidden_dim1, hidden_dim2, output_dim)\n",
    "\n",
    "# Определяем функцию потерь и оптимизатор\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Обучение модели (пример)\n",
    "def train(model, data_loader, criterion, optimizer, epochs=10):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        for inputs, labels in data_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# Извлечение векторов из скрытого слоя\n",
    "def get_hidden_vectors(model, inputs):\n",
    "    with torch.no_grad():\n",
    "        hidden_layer_output = torch.relu(model.hidden1(inputs))\n",
    "        return hidden_layer_output\n",
    "\n",
    "train(model, data_loader, criterion, optimizer)\n",
    "\n",
    "# Получение вектора пользователя\n",
    "user_data = torch.randn(1, input_dim)  # пример входных данных для одного пользователя\n",
    "user_vector = get_hidden_vectors(model, user_data)\n",
    "print(\"User vector from hidden layer:\", user_vector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "id": "ea39207b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_val = CustomDataset(X_val, target_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "id": "5b2e9811",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6983, 73)"
      ]
     },
     "execution_count": 594,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "id": "b5aef742",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем экземпляр Dataset для тестовых данных\n",
    "val_dataset = CustomDataset(X_val, target_column)\n",
    "\n",
    "# Создаем DataLoader для тестовых данных\n",
    "val_loader = DataLoader(val_dataset, batch_size=2, shuffle=False)\n",
    "\n",
    "# Применяем модель к тестовым данным\n",
    "model.eval()  # Устанавливаем модель в режим оценки\n",
    "\n",
    "y_val_pred = []\n",
    "with torch.no_grad():  # Отключаем градиенты для тестирования\n",
    "    for inputs, labels in val_loader:\n",
    "        outputs = model(inputs)  # Применяем модель к входным данным\n",
    "        _, predicted = torch.max(outputs, 1)  # Получаем индексы максимальных значений\n",
    "        y_val_pred.extend(predicted.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "id": "40bf3715",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6983"
      ]
     },
     "execution_count": 596,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_loader.dataset.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "id": "0d4661f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Делаем валидацию нашей модель\n",
    "y_val_word = pd.DataFrame()\n",
    "\n",
    "\n",
    "y_val_word['word'] = 'user_' + y_val.astype(str) \n",
    "\n",
    "y_val_word['true'] = y_val\n",
    "\n",
    "y_val_word['preds'] = y_val_pred\n",
    "\n",
    "y_val_pred_word = pd.DataFrame(y_val_word.groupby('word')[['true','preds']].agg(lambda x: x.value_counts().index[0]))\n",
    "\n",
    "y_val_pred_word['comp'] = y_val_pred_word['preds'] == y_val_pred_word['true']\n",
    "\n",
    "y_val_pred_word['norm'] = 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7245af",
   "metadata": {},
   "source": [
    "### Оцениваем качество"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e807fdf7-d115-43d7-b1b4-ad0e9545c526",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Делаем валидацию нашей модель\n",
    "\n",
    "# Создаем новые датасеты\n",
    "y_word = pd.DataFrame()\n",
    "y_val_word = pd.DataFrame()\n",
    "\n",
    "\n",
    "# Что типа id в тестовой выборке\n",
    "y_word['word'] = 'user_' + y.astype(str)\n",
    "y_val_word['word'] = 'user_' + y_val.astype(str) \n",
    "\n",
    "# Целевая переменная ground truth\n",
    "y_word['true'] = y\n",
    "y_val_word['true'] = y_val\n",
    "\n",
    "# Добавим предсказания\n",
    "y_word['preds'] = y_pred\n",
    "y_val_word['preds'] = y_val_pred\n",
    "\n",
    "\n",
    "\n",
    "# Делаем датасеты с предсказаниями\n",
    "y_pred_word = pd.DataFrame(y_word.groupby('word')[['true','preds']].agg(lambda x: x.value_counts().index[0]))\n",
    "y_val_pred_word = pd.DataFrame(y_val_word.groupby('word')[['true','preds']].agg(lambda x: x.value_counts().index[0]))\n",
    "\n",
    "# Добавляем сравнение с ground truth\n",
    "y_pred_word['comp'] = y_pred_word['preds'] == y_pred_word['true']\n",
    "y_val_pred_word['comp'] = y_val_pred_word['preds'] == y_val_pred_word['true']\n",
    "\n",
    "\n",
    "# Веса юзеров мы не знаем, давайте возьмем равные веса для простоты = 1. Можно и не брать пролли\n",
    "y_pred_word['norm'] = 1\n",
    "y_val_pred_word['norm'] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7b7f1106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Оценка train2 42 50 84.0\n"
     ]
    }
   ],
   "source": [
    "# Оцениваем на train\n",
    "\n",
    "true_answers = (y_pred_word['comp'] * y_pred_word['norm']).sum()\n",
    "total_answers = y_pred_word['norm'].sum()\n",
    "precent_true = round((true_answers/total_answers)*100, 1)\n",
    "\n",
    "print('Оценка train2', true_answers, total_answers, precent_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e40d16e1-e2e5-460b-89b2-4f1005dab98d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Оценка val 21 43 48.8\n"
     ]
    }
   ],
   "source": [
    "# Оцениваем на val\n",
    "\n",
    "true_answers_val = (y_val_pred_word['comp'] * y_val_pred_word['norm']).sum()\n",
    "total_answers_val = y_val_pred_word['norm'].sum()\n",
    "precent_true_val = round((true_answers_val/total_answers_val)*100, 1)\n",
    "\n",
    "print('Оценка val', true_answers_val, total_answers_val, precent_true_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54edd785",
   "metadata": {},
   "source": [
    "### Готовим сабмит"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "fd264328",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = all_data[all_data[\"user_id\"].notna()].shape[0]\n",
    "train_df = all_data[:n]\n",
    "test_df = all_data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8dddfa3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_df[\"user_id\"].astype(int)\n",
    "X_train = train_df.drop([\"user_id\", \"user_word\", \"ts\"], axis=1)\n",
    "X_test = test_df.drop([\"user_id\", \"user_word\", \"ts\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1badba0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_X = StandardScaler()\n",
    "scaler_X_test = StandardScaler()\n",
    "\n",
    "X_train = pd.DataFrame(scaler_X.fit_transform(X_train), columns=X_train.columns)\n",
    "X_test = pd.DataFrame(scaler_X_test.fit_transform(X_test), columns=X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "99e095c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = model.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = clf.predict(X_train)\n",
    "\n",
    "y_test_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 908,
   "id": "ae4f0c33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    18\n",
       "1    18\n",
       "2    18\n",
       "3    18\n",
       "4    18\n",
       "Name: user_id, dtype: int32"
      ]
     },
     "execution_count": 908,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "218907c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>true</th>\n",
       "      <th>preds_0</th>\n",
       "      <th>preds_1</th>\n",
       "      <th>preds_2</th>\n",
       "      <th>preds_3</th>\n",
       "      <th>preds_4</th>\n",
       "      <th>preds_5</th>\n",
       "      <th>preds_6</th>\n",
       "      <th>preds_7</th>\n",
       "      <th>preds_8</th>\n",
       "      <th>...</th>\n",
       "      <th>preds_46</th>\n",
       "      <th>preds_47</th>\n",
       "      <th>preds_48</th>\n",
       "      <th>preds_49</th>\n",
       "      <th>preds_50</th>\n",
       "      <th>preds_51</th>\n",
       "      <th>preds_52</th>\n",
       "      <th>preds_53</th>\n",
       "      <th>preds_54</th>\n",
       "      <th>preds_55</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>aucroc</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.141463</td>\n",
       "      <td>0.053659</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009756</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009756</td>\n",
       "      <td>0.092683</td>\n",
       "      <td>0.034146</td>\n",
       "      <td>0.009756</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009756</td>\n",
       "      <td>0.039024</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>binary</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.024936</td>\n",
       "      <td>0.009924</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.062850</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000509</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.037659</td>\n",
       "      <td>0.003053</td>\n",
       "      <td>0.000509</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.070229</td>\n",
       "      <td>0.003308</td>\n",
       "      <td>0.003562</td>\n",
       "      <td>0.000509</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blue</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.108333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>categorical</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002703</td>\n",
       "      <td>0.000386</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001931</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000386</td>\n",
       "      <td>0.027799</td>\n",
       "      <td>0.008880</td>\n",
       "      <td>0.001544</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001544</td>\n",
       "      <td>0.013900</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005019</td>\n",
       "      <td>0.000772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coefficient</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.075385</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004615</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.063077</td>\n",
       "      <td>0.001538</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006154</td>\n",
       "      <td>0.001538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>collinear</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.039210</td>\n",
       "      <td>0.017933</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000304</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.084195</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008815</td>\n",
       "      <td>0.078723</td>\n",
       "      <td>0.012462</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019453</td>\n",
       "      <td>0.015805</td>\n",
       "      <td>0.001216</td>\n",
       "      <td>0.000912</td>\n",
       "      <td>0.001824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>distributed</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.152033</td>\n",
       "      <td>0.025203</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041463</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.052846</td>\n",
       "      <td>0.008130</td>\n",
       "      <td>0.132520</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012195</td>\n",
       "      <td>0.068293</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.073171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epsilon</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005121</td>\n",
       "      <td>0.094340</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000270</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.066038</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.035310</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019407</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.060377</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002628</td>\n",
       "      <td>0.004336</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.225756</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003548</td>\n",
       "      <td>0.018397</td>\n",
       "      <td>0.002891</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.024310</td>\n",
       "      <td>0.002234</td>\n",
       "      <td>0.068725</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fit</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.110363</td>\n",
       "      <td>0.099482</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.268912</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010881</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010363</td>\n",
       "      <td>0.014508</td>\n",
       "      <td>0.025389</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005699</td>\n",
       "      <td>0.012435</td>\n",
       "      <td>0.003109</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.024352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gini</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.079167</td>\n",
       "      <td>0.227083</td>\n",
       "      <td>0.001736</td>\n",
       "      <td>0.152083</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009375</td>\n",
       "      <td>0.001042</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>0.042014</td>\n",
       "      <td>0.032986</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013542</td>\n",
       "      <td>0.007292</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>independent</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.078457</td>\n",
       "      <td>0.075563</td>\n",
       "      <td>0.001608</td>\n",
       "      <td>0.022186</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.077814</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001608</td>\n",
       "      <td>0.076849</td>\n",
       "      <td>0.035370</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010932</td>\n",
       "      <td>0.007395</td>\n",
       "      <td>0.019293</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lasso</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.070588</td>\n",
       "      <td>0.023529</td>\n",
       "      <td>0.002941</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011765</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.044118</td>\n",
       "      <td>0.026471</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014706</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.026471</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>linear</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.044076</td>\n",
       "      <td>0.017536</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.118009</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010900</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006635</td>\n",
       "      <td>0.001422</td>\n",
       "      <td>0.038389</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005213</td>\n",
       "      <td>0.035071</td>\n",
       "      <td>0.005687</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.057820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>logistic</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loss</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.018913</td>\n",
       "      <td>0.003018</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.155131</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001207</td>\n",
       "      <td>0.010262</td>\n",
       "      <td>0.004829</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.068008</td>\n",
       "      <td>0.001811</td>\n",
       "      <td>0.073843</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>matrix</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.020482</td>\n",
       "      <td>0.007229</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.043976</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.056627</td>\n",
       "      <td>0.141566</td>\n",
       "      <td>0.065060</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015060</td>\n",
       "      <td>0.045783</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000602</td>\n",
       "      <td>0.022892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>minimization</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.069697</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004040</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015152</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.134343</td>\n",
       "      <td>0.053535</td>\n",
       "      <td>0.092929</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017172</td>\n",
       "      <td>0.139394</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mse</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.073832</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001869</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020561</td>\n",
       "      <td>0.013084</td>\n",
       "      <td>0.088785</td>\n",
       "      <td>0.004673</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010280</td>\n",
       "      <td>0.092523</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ols</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.036552</td>\n",
       "      <td>0.000690</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020690</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022759</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044138</td>\n",
       "      <td>0.000690</td>\n",
       "      <td>0.048966</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012414</td>\n",
       "      <td>0.087586</td>\n",
       "      <td>0.005517</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.070175</td>\n",
       "      <td>0.017544</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007018</td>\n",
       "      <td>0.005263</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.024561</td>\n",
       "      <td>0.070175</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007018</td>\n",
       "      <td>0.026316</td>\n",
       "      <td>0.003509</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predict</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.037719</td>\n",
       "      <td>0.010526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033772</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023246</td>\n",
       "      <td>0.101754</td>\n",
       "      <td>0.048684</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011842</td>\n",
       "      <td>0.049561</td>\n",
       "      <td>0.006140</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pvalue</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.038172</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006452</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.181183</td>\n",
       "      <td>0.001075</td>\n",
       "      <td>0.095699</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.198925</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.041038</td>\n",
       "      <td>0.015094</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.032075</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.037736</td>\n",
       "      <td>0.138679</td>\n",
       "      <td>0.029245</td>\n",
       "      <td>0.000943</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019340</td>\n",
       "      <td>0.062736</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.049057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.105677</td>\n",
       "      <td>0.347598</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.241921</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005240</td>\n",
       "      <td>0.011354</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011790</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000437</td>\n",
       "      <td>0.003057</td>\n",
       "      <td>0.006987</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014410</td>\n",
       "      <td>0.000437</td>\n",
       "      <td>0.001310</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.045415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>regression</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.052830</td>\n",
       "      <td>0.005660</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.047170</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.037736</td>\n",
       "      <td>0.064151</td>\n",
       "      <td>0.149057</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009434</td>\n",
       "      <td>0.064151</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>residual</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.043421</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.154825</td>\n",
       "      <td>0.037281</td>\n",
       "      <td>0.084649</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.040789</td>\n",
       "      <td>0.087281</td>\n",
       "      <td>0.008772</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.042982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ridge</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.065333</td>\n",
       "      <td>0.024667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.092000</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.040667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022667</td>\n",
       "      <td>0.039333</td>\n",
       "      <td>0.008667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sigmoid</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002018</td>\n",
       "      <td>0.010538</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.133408</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000224</td>\n",
       "      <td>0.023543</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.088565</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.424664</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>significant</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.073973</td>\n",
       "      <td>0.011986</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021918</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.070890</td>\n",
       "      <td>0.029795</td>\n",
       "      <td>0.049315</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031164</td>\n",
       "      <td>0.054110</td>\n",
       "      <td>0.020205</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.032877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.069828</td>\n",
       "      <td>0.023276</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000862</td>\n",
       "      <td>0.005172</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000862</td>\n",
       "      <td>0.114655</td>\n",
       "      <td>0.047414</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001724</td>\n",
       "      <td>0.001724</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033621</td>\n",
       "      <td>0.026724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tstat</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.044056</td>\n",
       "      <td>0.002797</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027972</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031469</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.145455</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020280</td>\n",
       "      <td>0.124476</td>\n",
       "      <td>0.002797</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.012579</td>\n",
       "      <td>0.014465</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.106289</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000629</td>\n",
       "      <td>0.056604</td>\n",
       "      <td>0.001258</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.056918</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004088</td>\n",
       "      <td>0.001258</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.114035</td>\n",
       "      <td>0.024561</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008772</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017544</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019298</td>\n",
       "      <td>0.056140</td>\n",
       "      <td>0.091228</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019298</td>\n",
       "      <td>0.084211</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019298</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              true   preds_0   preds_1   preds_2   preds_3  preds_4   preds_5  \\\n",
       "word                                                                            \n",
       "aucroc         NaN  0.141463  0.053659  0.000000  0.009756      0.0  0.000000   \n",
       "binary         NaN  0.024936  0.009924  0.000000  0.000000      0.0  0.000000   \n",
       "blue           NaN  0.016667  0.000000  0.000000  0.000000      0.0  0.000000   \n",
       "categorical    NaN  0.002703  0.000386  0.000000  0.000000      0.0  0.000000   \n",
       "coefficient    NaN  0.000000  0.075385  0.000000  0.000000      0.0  0.000000   \n",
       "collinear      NaN  0.039210  0.017933  0.000000  0.000304      0.0  0.000000   \n",
       "distributed    NaN  0.152033  0.025203  0.000000  0.041463      0.0  0.000000   \n",
       "epsilon        NaN  0.005121  0.094340  0.000000  0.000270      0.0  0.000000   \n",
       "f1             NaN  0.002628  0.004336  0.000000  0.000000      0.0  0.000000   \n",
       "fit            NaN  0.110363  0.099482  0.000000  0.268912      0.0  0.000000   \n",
       "gini           NaN  0.079167  0.227083  0.001736  0.152083      0.0  0.000000   \n",
       "independent    NaN  0.078457  0.075563  0.001608  0.022186      0.0  0.000000   \n",
       "lasso          NaN  0.070588  0.023529  0.002941  0.050000      0.0  0.000000   \n",
       "linear         NaN  0.044076  0.017536  0.000000  0.118009      0.0  0.000000   \n",
       "logistic       NaN  0.000000  0.000000  0.000000  0.000000      0.0  0.000000   \n",
       "loss           NaN  0.018913  0.003018  0.000000  0.001006      0.0  0.000000   \n",
       "matrix         NaN  0.020482  0.007229  0.000000  0.000000      0.0  0.000000   \n",
       "minimization   NaN  0.069697  0.000000  0.000000  0.004040      0.0  0.000000   \n",
       "mse            NaN  0.073832  0.000000  0.000000  0.000000      0.0  0.000000   \n",
       "ols            NaN  0.036552  0.000690  0.000000  0.020690      0.0  0.000000   \n",
       "precision      NaN  0.070175  0.017544  0.000000  0.005263      0.0  0.000000   \n",
       "predict        NaN  0.037719  0.010526  0.000000  0.000000      0.0  0.000000   \n",
       "pvalue         NaN  0.038172  0.000000  0.000000  0.006452      0.0  0.000000   \n",
       "r2             NaN  0.041038  0.015094  0.000000  0.000000      0.0  0.000000   \n",
       "recall         NaN  0.105677  0.347598  0.000000  0.241921      0.0  0.005240   \n",
       "regression     NaN  0.052830  0.005660  0.000000  0.000000      0.0  0.000000   \n",
       "residual       NaN  0.043421  0.008333  0.000000  0.000000      0.0  0.000000   \n",
       "ridge          NaN  0.065333  0.024667  0.000000  0.025333      0.0  0.000000   \n",
       "sigmoid        NaN  0.002018  0.010538  0.000000  0.000000      0.0  0.000000   \n",
       "significant    NaN  0.073973  0.011986  0.000000  0.021918      0.0  0.000000   \n",
       "target         NaN  0.069828  0.023276  0.000000  0.000000      0.0  0.000862   \n",
       "tstat          NaN  0.044056  0.002797  0.000000  0.027972      0.0  0.000000   \n",
       "x              NaN  0.012579  0.014465  0.000000  0.000000      0.0  0.000000   \n",
       "y              NaN  0.114035  0.024561  0.000000  0.008772      0.0  0.000000   \n",
       "\n",
       "               preds_6   preds_7   preds_8  ...  preds_46  preds_47  preds_48  \\\n",
       "word                                        ...                                 \n",
       "aucroc        0.000000  0.000000  0.000000  ...  0.009756  0.092683  0.034146   \n",
       "binary        0.062850  0.000000  0.000509  ...  0.000000  0.037659  0.003053   \n",
       "blue          0.000000  0.000000  0.108333  ...  0.000000  0.033333  0.033333   \n",
       "categorical   0.001931  0.000000  0.000000  ...  0.000386  0.027799  0.008880   \n",
       "coefficient   0.004615  0.000000  0.000000  ...  0.000000  0.063077  0.001538   \n",
       "collinear     0.084195  0.000000  0.000000  ...  0.008815  0.078723  0.012462   \n",
       "distributed   0.000000  0.000000  0.000000  ...  0.052846  0.008130  0.132520   \n",
       "epsilon       0.066038  0.000000  0.000000  ...  0.000000  0.035310  0.000000   \n",
       "f1            0.225756  0.000000  0.000000  ...  0.003548  0.018397  0.002891   \n",
       "fit           0.010881  0.000000  0.000000  ...  0.010363  0.014508  0.025389   \n",
       "gini          0.009375  0.001042  0.000000  ...  0.000347  0.042014  0.032986   \n",
       "independent   0.077814  0.000000  0.000000  ...  0.001608  0.076849  0.035370   \n",
       "lasso         0.000000  0.000000  0.011765  ...  0.000000  0.044118  0.026471   \n",
       "linear        0.010900  0.000000  0.000000  ...  0.006635  0.001422  0.038389   \n",
       "logistic      0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
       "loss          0.155131  0.000000  0.000000  ...  0.001207  0.010262  0.004829   \n",
       "matrix        0.043976  0.000000  0.000000  ...  0.056627  0.141566  0.065060   \n",
       "minimization  0.015152  0.000000  0.000000  ...  0.134343  0.053535  0.092929   \n",
       "mse           0.001869  0.000000  0.000000  ...  0.020561  0.013084  0.088785   \n",
       "ols           0.022759  0.000000  0.000000  ...  0.044138  0.000690  0.048966   \n",
       "precision     0.000000  0.007018  0.005263  ...  0.000000  0.024561  0.070175   \n",
       "predict       0.033772  0.000000  0.000000  ...  0.023246  0.101754  0.048684   \n",
       "pvalue        0.000000  0.000000  0.000000  ...  0.181183  0.001075  0.095699   \n",
       "r2            0.032075  0.000000  0.000000  ...  0.037736  0.138679  0.029245   \n",
       "recall        0.011354  0.000000  0.011790  ...  0.000437  0.003057  0.006987   \n",
       "regression    0.047170  0.000000  0.000000  ...  0.037736  0.064151  0.149057   \n",
       "residual      0.010526  0.000000  0.000000  ...  0.154825  0.037281  0.084649   \n",
       "ridge         0.019333  0.000000  0.000000  ...  0.092000  0.016667  0.040667   \n",
       "sigmoid       0.133408  0.000000  0.000000  ...  0.000224  0.023543  0.000000   \n",
       "significant   0.050000  0.000000  0.000000  ...  0.070890  0.029795  0.049315   \n",
       "target        0.005172  0.000000  0.000000  ...  0.000862  0.114655  0.047414   \n",
       "tstat         0.000000  0.000000  0.000000  ...  0.031469  0.000000  0.145455   \n",
       "x             0.106289  0.000000  0.000000  ...  0.000629  0.056604  0.001258   \n",
       "y             0.017544  0.000000  0.000000  ...  0.019298  0.056140  0.091228   \n",
       "\n",
       "              preds_49  preds_50  preds_51  preds_52  preds_53  preds_54  \\\n",
       "word                                                                       \n",
       "aucroc        0.009756  0.000000  0.009756  0.039024  0.000000  0.000000   \n",
       "binary        0.000509  0.000000  0.070229  0.003308  0.003562  0.000509   \n",
       "blue          0.000000  0.008333  0.000000  0.000000  0.000000  0.083333   \n",
       "categorical   0.001544  0.000000  0.001544  0.013900  0.000000  0.005019   \n",
       "coefficient   0.000000  0.000000  0.000000  0.000000  0.000000  0.006154   \n",
       "collinear     0.000000  0.000000  0.019453  0.015805  0.001216  0.000912   \n",
       "distributed   0.000000  0.000000  0.012195  0.068293  0.000000  0.000000   \n",
       "epsilon       0.000000  0.000000  0.019407  0.000000  0.060377  0.000000   \n",
       "f1            0.000000  0.000000  0.024310  0.002234  0.068725  0.000000   \n",
       "fit           0.000000  0.000000  0.005699  0.012435  0.003109  0.000000   \n",
       "gini          0.000000  0.000000  0.013542  0.007292  0.000347  0.000000   \n",
       "independent   0.000000  0.000000  0.010932  0.007395  0.019293  0.000000   \n",
       "lasso         0.000000  0.000000  0.000000  0.014706  0.000000  0.026471   \n",
       "linear        0.000000  0.000000  0.005213  0.035071  0.005687  0.000000   \n",
       "logistic      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "loss          0.000000  0.000000  0.068008  0.001811  0.073843  0.000000   \n",
       "matrix        0.000000  0.000000  0.015060  0.045783  0.000000  0.000602   \n",
       "minimization  0.000000  0.000000  0.017172  0.139394  0.000000  0.000000   \n",
       "mse           0.004673  0.000000  0.010280  0.092523  0.000000  0.000000   \n",
       "ols           0.000000  0.000000  0.012414  0.087586  0.005517  0.000000   \n",
       "precision     0.000000  0.000000  0.007018  0.026316  0.003509  0.000000   \n",
       "predict       0.000000  0.000000  0.011842  0.049561  0.006140  0.000000   \n",
       "pvalue        0.000000  0.000000  0.000000  0.198925  0.000000  0.000000   \n",
       "r2            0.000943  0.000000  0.019340  0.062736  0.000000  0.000000   \n",
       "recall        0.000000  0.000000  0.014410  0.000437  0.001310  0.000000   \n",
       "regression    0.000000  0.000000  0.009434  0.064151  0.000000  0.000000   \n",
       "residual      0.000000  0.000000  0.040789  0.087281  0.008772  0.000000   \n",
       "ridge         0.000000  0.000000  0.022667  0.039333  0.008667  0.000000   \n",
       "sigmoid       0.000000  0.000000  0.088565  0.000000  0.424664  0.000000   \n",
       "significant   0.000000  0.000000  0.031164  0.054110  0.020205  0.000000   \n",
       "target        0.000000  0.000000  0.001724  0.001724  0.000000  0.033621   \n",
       "tstat         0.000000  0.000000  0.020280  0.124476  0.002797  0.000000   \n",
       "x             0.000000  0.000000  0.056918  0.000000  0.004088  0.001258   \n",
       "y             0.000000  0.000000  0.019298  0.084211  0.000000  0.000000   \n",
       "\n",
       "              preds_55  \n",
       "word                    \n",
       "aucroc        0.017073  \n",
       "binary        0.000000  \n",
       "blue          0.000000  \n",
       "categorical   0.000772  \n",
       "coefficient   0.001538  \n",
       "collinear     0.001824  \n",
       "distributed   0.073171  \n",
       "epsilon       0.000000  \n",
       "f1            0.000131  \n",
       "fit           0.024352  \n",
       "gini          0.005208  \n",
       "independent   0.001286  \n",
       "lasso         0.000000  \n",
       "linear        0.057820  \n",
       "logistic      0.000000  \n",
       "loss          0.000604  \n",
       "matrix        0.022892  \n",
       "minimization  0.027273  \n",
       "mse           0.012150  \n",
       "ols           0.008966  \n",
       "precision     0.000000  \n",
       "predict       0.003509  \n",
       "pvalue        0.018817  \n",
       "r2            0.049057  \n",
       "recall        0.045415  \n",
       "regression    0.033962  \n",
       "residual      0.042982  \n",
       "ridge         0.041333  \n",
       "sigmoid       0.001570  \n",
       "significant   0.032877  \n",
       "target        0.026724  \n",
       "tstat         0.001399  \n",
       "x             0.000000  \n",
       "y             0.019298  \n",
       "\n",
       "[34 rows x 57 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict_proba(X_train.head(5))\n",
    "\n",
    "y_pred_proba = clf.predict_proba(X_test)\n",
    "\n",
    "y_word = pd.DataFrame()\n",
    "y_word['word'] = test_df[\"user_word\"]\n",
    "y_word['true'] = y\n",
    "\n",
    "\n",
    "for i in range(y_pred_proba.shape[1]):\n",
    "    col = y_pred_proba[:,i]\n",
    "    y_word['preds_' + str(i)] = col\n",
    "\n",
    "\n",
    "y_word.groupby([\"word\"]).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a1227e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_words = pd.DataFrame()\n",
    "\n",
    "test_words['user_word'] = test['user_word']\n",
    "test_words['preds'] = y_test_pred\n",
    "\n",
    "comp_df_test = pd.DataFrame(test_words.groupby('user_word')['preds'].agg(lambda x: x.value_counts().index[0]))\n",
    "\n",
    "comp_df_test.to_csv('answer.csv') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 897,
   "id": "52f31e88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'zip' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "! zip answer.zip answer.csv # Подготовка файла для отправки"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
