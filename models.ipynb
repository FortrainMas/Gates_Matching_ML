{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#models\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### We will use last month records for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation percent:  0.2286883903717046\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(\"data/train_preprocessed.csv\")\n",
    "\n",
    "val_index = train['ts'] > '2022-11-30'\n",
    "validation = train[val_index].copy()\n",
    "train = train[~val_index].copy()\n",
    "\n",
    "print(\"Validation percent: \", validation.shape[0] / train.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop(['user_id', 'ts'], axis=1)\n",
    "y = train['user_id']\n",
    "\n",
    "X_val = validation.drop(['user_id', 'ts'], axis=1)\n",
    "y_val = validation['user_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Also we will scale everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_X = StandardScaler()\n",
    "scaler_X_val = StandardScaler()\n",
    "\n",
    "X = pd.DataFrame(scaler_X.fit_transform(X), columns=X.columns)\n",
    "X_val = pd.DataFrame(scaler_X_val.fit_transform(X_val), columns=X_val.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Try various models with different hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Деревья уходили в переобучения. И ничего хорошего не выходило\n",
    "model = KNeighborsClassifier(n_neighbors=10, metric='cosine') #104 14\n",
    "#model = LogisticRegression()\n",
    "#model = CatBoostClassifier(learning_rate=0.001, depth=6, l2_leaf_reg=3, iterations=1000)\n",
    "#model = RandomForestClassifier(n_estimators=100, class_weight='balanced', max_depth=21, criterion='entropy')\n",
    "clf = model.fit(X, y)\n",
    "\n",
    "y_pred = clf.predict(X)\n",
    "\n",
    "y_val_pred = clf.predict(X_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Evaluate quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Делаем валидацию нашей модель\n",
    "\n",
    "# Создаем новые датасеты\n",
    "y_word = pd.DataFrame()\n",
    "y_val_word = pd.DataFrame()\n",
    "\n",
    "\n",
    "# Что типа id в тестовой выборке\n",
    "y_word['word'] = 'user_' + y.astype(str)\n",
    "y_val_word['word'] = 'user_' + y_val.astype(str) \n",
    "\n",
    "# Целевая переменная ground truth\n",
    "y_word['true'] = y\n",
    "y_val_word['true'] = y_val\n",
    "\n",
    "# Добавим предсказания\n",
    "y_word['preds'] = y_pred\n",
    "y_val_word['preds'] = y_val_pred\n",
    "\n",
    "\n",
    "\n",
    "# Делаем датасеты с предсказаниями\n",
    "y_pred_word = pd.DataFrame(y_word.groupby('word')[['true','preds']].agg(lambda x: x.value_counts().index[0]))\n",
    "y_val_pred_word = pd.DataFrame(y_val_word.groupby('word')[['true','preds']].agg(lambda x: x.value_counts().index[0]))\n",
    "\n",
    "# Добавляем сравнение с ground truth\n",
    "y_pred_word['comp'] = y_pred_word['preds'] == y_pred_word['true']\n",
    "y_val_pred_word['comp'] = y_val_pred_word['preds'] == y_val_pred_word['true']\n",
    "\n",
    "\n",
    "# Веса юзеров мы не знаем, давайте возьмем равные веса для простоты = 1. Можно и не брать пролли\n",
    "y_pred_word['norm'] = 1\n",
    "y_val_pred_word['norm'] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Оценка train2 50 50 100.0\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on train\n",
    "\n",
    "true_answers = (y_pred_word['comp'] * y_pred_word['norm']).sum()\n",
    "total_answers = y_pred_word['norm'].sum()\n",
    "precent_true = round((true_answers/total_answers)*100, 1)\n",
    "\n",
    "print('Accuracy train2', true_answers, total_answers, precent_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy val 34 43 79.1\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on val\n",
    "\n",
    "true_answers_val = (y_val_pred_word['comp'] * y_val_pred_word['norm']).sum()\n",
    "total_answers_val = y_val_pred_word['norm'].sum()\n",
    "precent_true_val = round((true_answers_val/total_answers_val)*100, 1)\n",
    "\n",
    "print('Accuracy val', true_answers_val, total_answers_val, precent_true_val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
